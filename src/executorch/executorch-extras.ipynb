{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "torch.manual_seed(2000)\n",
    "np.random.seed(2000)\n",
    "random.seed(2000)\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import traceback as tb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch._export import capture_pre_autograd_graph\n",
    "from torch.export import export, ExportedProgram\n",
    "\n",
    "def f(x, y):\n",
    "    return x + y\n",
    "example_args = (torch.randn(3, 3), torch.randn(3, 3))\n",
    "\n",
    "pre_autograd_aten_dialect = capture_pre_autograd_graph(f, example_args)\n",
    "aten_dialect: ExportedProgram = export(pre_autograd_aten_dialect, example_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some details\n",
    "\n",
    "Different dimensions than the ones expected from our model (obviously) break things"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Works correctly\n",
    "print(aten_dialect(torch.ones(3, 3), torch.ones(3, 3)))\n",
    "\n",
    "# Errors\n",
    "try:\n",
    "    print(aten_dialect(torch.ones(3, 2), torch.ones(3, 2)))\n",
    "except Exception as e:\n",
    "    tb.print_exc(limit=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But there can be some dynamism. We can put some constraints on the inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.export import dynamic_dim\n",
    "constraints = [\n",
    "    # Input 0, dimension 1 is dynamic\n",
    "    dynamic_dim(example_args[0], 1),\n",
    "    # Input 0, dimension 1 must be greater than or equal to 1\n",
    "    1 <= dynamic_dim(example_args[0], 1),\n",
    "    # Input 0, dimension 1 must be less than or equal to 10\n",
    "    dynamic_dim(example_args[0], 1) <= 10,\n",
    "    # Input 1, dimension 1 is equal to input 0, dimension 1\n",
    "    dynamic_dim(example_args[1], 1) == dynamic_dim(example_args[0], 1),\n",
    "]\n",
    "pre_autograd_aten_dialect = capture_pre_autograd_graph(\n",
    "    f, example_args, constraints=constraints\n",
    ")\n",
    "aten_dialect: ExportedProgram = export(f, example_args, constraints=constraints)\n",
    "\n",
    "# Works correctly\n",
    "print(aten_dialect(torch.ones(3, 3), torch.ones(3, 3)))\n",
    "print(aten_dialect(torch.ones(3, 2), torch.ones(3, 2)))\n",
    "\n",
    "# Errors because it violates our constraint that input 0, dim 1 <= 10\n",
    "try:\n",
    "    print(aten_dialect(torch.ones(3, 15), torch.ones(3, 15)))\n",
    "except Exception:\n",
    "    tb.print_exc(limit=1)\n",
    "    \n",
    "# Errors because it violates our constraint that input 0, dim 1 == input 1, dim 1\n",
    "try:\n",
    "    print(aten_dialect(torch.ones(3, 3), torch.ones(3, 2)))\n",
    "except Exception:\n",
    "    tb.print_exc(limit=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "executorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
