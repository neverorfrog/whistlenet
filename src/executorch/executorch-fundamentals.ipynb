{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "from datamodules.mnist import MnistDataset\n",
    "from core.trainer import Trainer\n",
    "from models import CNN\n",
    "from models import MNIST_CONFIG as config\n",
    "import torch\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from core import project_root\n",
    "projroot = project_root()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATA SAVED!\n",
      "N Examples: 54000\n",
      "N Classes: 10\n",
      "Classes: [0 1 2 3 4 5 6 7 8 9]\n",
      " - Class 0: 5364 (9.933333333333334)\n",
      " - Class 1: 6066 (11.233333333333333)\n",
      " - Class 2: 5320 (9.851851851851851)\n",
      " - Class 3: 5511 (10.205555555555556)\n",
      " - Class 4: 5274 (9.766666666666666)\n",
      " - Class 5: 4867 (9.012962962962963)\n",
      " - Class 6: 5331 (9.872222222222222)\n",
      " - Class 7: 5649 (10.461111111111112)\n",
      " - Class 8: 5272 (9.762962962962964)\n",
      " - Class 9: 5346 (9.9)\n",
      "MODEL LOADED!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7eae1af08400>]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = MnistDataset(tobeloaded=False, params=config.DATA_PARAMS)\n",
    "dataset.summarize()\n",
    "model = CNN(\"mnist\", num_classes=10)\n",
    "trainer = Trainer(params=config.TRAIN_PARAMS)\n",
    "model.load(\"mnist\")\n",
    "# trainer.fit(model,dataset)\n",
    "plt.plot(model.test_scores, label=f'mnist - test scores')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install\n",
    "\n",
    "### [Getting Started](https://pytorch.org/executorch/stable/getting-started-setup.html)\n",
    "### [Building with CMake](https://pytorch.org/executorch/stable/runtime-build-and-cross-compilation.html)\n",
    "\n",
    "# Toy Example \n",
    "### [PyTorch Source](https://pytorch.org/executorch/stable/tutorials/export-to-executorch-tutorial.html)\n",
    "\n",
    "![picture 1](images/workflow.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0014,  0.3307, -0.0067,  1.3315,  0.0000,  1.3400,  0.6919, -0.0053,\n",
       "         -0.0176,  0.1893]], grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class FullyConnected(torch.nn.Module):\n",
    "    #Fully Connected layers    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        fc_dims = [4,1]\n",
    "        self.activation = nn.ReLU()\n",
    "        self.example_args = (torch.randn(1, 4),)\n",
    "        fc_layers = []\n",
    "        for i in range(len(fc_dims)-1):\n",
    "            fc_layers.append(nn.Linear(fc_dims[i],fc_dims[i+1],bias=True))\n",
    "            fc_layers.append(self.activation)\n",
    "        self.fc = nn.Sequential(*fc_layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc(x)\n",
    "    \n",
    "class Add(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.example_args = (torch.randn(1, 4), torch.randn(1, 4))\n",
    "        \n",
    "    def forward(self,x,y):\n",
    "        return x + y\n",
    "    \n",
    "# m = FullyConnected()\n",
    "m = CNN(\"mnist\",num_classes=10)\n",
    "m(*m.example_args)\n",
    "# m.load(\"mnist\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Pre-Autograd ATen Dialect\n",
    "    - Trace a module before any pre-autograd decomposition is run. Later this API will be changed like stated [here](https://github.com/pytorch/executorch/issues/290)\n",
    "        - Tracing means converting a PyTorch model into a more efficient, serialized format suitable for deployment in production or environments where Python might not be available.\n",
    "    - The result is still nn.Module but only with ATen operations, which are safe for eager mode training\n",
    "        - Eager mode training means we are still in an imperative fashion\n",
    "    - We will print the graph, represented through [Torch Fx](https://pytorch.org/docs/stable/fx.html#module-torch.fx), in a table to explicitly represent inputs, operations and outputs (more info [here](https://pytorch.org/docs/stable/fx.html#torch.fx.Node))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-Autograd ATen Dialect Graph\n",
      "opcode         name              target                   args                                              kwargs\n",
      "-------------  ----------------  -----------------------  ------------------------------------------------  -------------------------------------------------------------------------------\n",
      "placeholder    arg0_1            arg0                     ()                                                {}\n",
      "call_function  to                aten.to.dtype            (arg0_1, torch.float32)                           {}\n",
      "call_function  to_1              aten.to.dtype_layout     (to,)                                             {'dtype': torch.float32, 'layout': torch.strided, 'device': device(type='cpu')}\n",
      "get_attr       _param_constant0  conv_0_weight            ()                                                {}\n",
      "get_attr       _param_constant1  conv_0_bias              ()                                                {}\n",
      "call_function  conv2d            aten.conv2d.default      (to_1, _param_constant0, _param_constant1)        {}\n",
      "call_function  leaky_relu        aten.leaky_relu.default  (conv2d,)                                         {}\n",
      "call_function  max_pool2d        aten.max_pool2d.default  (leaky_relu, [2, 2], [2, 2])                      {}\n",
      "get_attr       _param_constant2  conv_3_weight            ()                                                {}\n",
      "get_attr       _param_constant3  conv_3_bias              ()                                                {}\n",
      "call_function  conv2d_1          aten.conv2d.default      (max_pool2d, _param_constant2, _param_constant3)  {}\n",
      "call_function  leaky_relu_1      aten.leaky_relu.default  (conv2d_1,)                                       {}\n",
      "call_function  max_pool2d_1      aten.max_pool2d.default  (leaky_relu_1, [2, 2], [2, 2])                    {}\n",
      "call_function  flatten           aten.flatten.using_ints  (max_pool2d_1, 1)                                 {}\n",
      "get_attr       _param_constant4  fc_0_weight              ()                                                {}\n",
      "get_attr       _param_constant5  fc_0_bias                ()                                                {}\n",
      "call_function  linear            aten.linear.default      (flatten, _param_constant4, _param_constant5)     {}\n",
      "call_function  leaky_relu_2      aten.leaky_relu.default  (linear,)                                         {}\n",
      "call_function  dropout           aten.dropout.default     (leaky_relu_2, 0.1, True)                         {}\n",
      "output         output            output                   ([dropout],)                                      {}\n"
     ]
    }
   ],
   "source": [
    "from torch._export import capture_pre_autograd_graph\n",
    "pre_autograd_aten_dialect = capture_pre_autograd_graph(m, m.example_args)\n",
    "print(\"Pre-Autograd ATen Dialect Graph\")\n",
    "pre_autograd_aten_dialect.graph.print_tabular()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Quantization (optional)\n",
    "    - Lower the precision, maintaining the accuracy high enough\n",
    "    - Goal is to enhance memory and computational efficiency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantized Graph\n",
      "opcode         name                             target                                              args                                                                                  kwargs\n",
      "-------------  -------------------------------  --------------------------------------------------  ------------------------------------------------------------------------------------  -------------------------------------------------------------------------------\n",
      "placeholder    arg0_1                           arg0                                                ()                                                                                    {}\n",
      "call_function  to                               aten.to.dtype                                       (arg0_1, torch.float32)                                                               {}\n",
      "call_function  to_1                             aten.to.dtype_layout                                (to,)                                                                                 {'dtype': torch.float32, 'layout': torch.strided, 'device': device(type='cpu')}\n",
      "call_function  quantize_per_tensor_default      quantized_decomposed.quantize_per_tensor.default    (to_1, 1.0, 0, -128, 127, torch.int8)                                                 {}\n",
      "call_function  dequantize_per_tensor_default    quantized_decomposed.dequantize_per_tensor.default  (quantize_per_tensor_default, 1.0, 0, -128, 127, torch.int8)                          {}\n",
      "get_attr       _frozen_param0                   _frozen_param0                                      ()                                                                                    {}\n",
      "call_function  dequantize_per_tensor_default_1  quantized_decomposed.dequantize_per_tensor.default  (_frozen_param0, 1.0, 0, -127, 127, torch.int8)                                       {}\n",
      "get_attr       _param_constant1                 conv_0_bias                                         ()                                                                                    {}\n",
      "call_function  conv2d                           aten.conv2d.default                                 (dequantize_per_tensor_default, dequantize_per_tensor_default_1, _param_constant1)    {}\n",
      "call_function  quantize_per_tensor_default_2    quantized_decomposed.quantize_per_tensor.default    (conv2d, 1.0, 0, -128, 127, torch.int8)                                               {}\n",
      "call_function  dequantize_per_tensor_default_2  quantized_decomposed.dequantize_per_tensor.default  (quantize_per_tensor_default_2, 1.0, 0, -128, 127, torch.int8)                        {}\n",
      "call_function  leaky_relu                       aten.leaky_relu.default                             (dequantize_per_tensor_default_2,)                                                    {}\n",
      "call_function  max_pool2d                       aten.max_pool2d.default                             (leaky_relu, [2, 2], [2, 2])                                                          {}\n",
      "call_function  quantize_per_tensor_default_3    quantized_decomposed.quantize_per_tensor.default    (max_pool2d, 1.0, 0, -128, 127, torch.int8)                                           {}\n",
      "call_function  dequantize_per_tensor_default_3  quantized_decomposed.dequantize_per_tensor.default  (quantize_per_tensor_default_3, 1.0, 0, -128, 127, torch.int8)                        {}\n",
      "get_attr       _frozen_param1                   _frozen_param1                                      ()                                                                                    {}\n",
      "call_function  dequantize_per_tensor_default_4  quantized_decomposed.dequantize_per_tensor.default  (_frozen_param1, 1.0, 0, -127, 127, torch.int8)                                       {}\n",
      "get_attr       _param_constant3                 conv_3_bias                                         ()                                                                                    {}\n",
      "call_function  conv2d_1                         aten.conv2d.default                                 (dequantize_per_tensor_default_3, dequantize_per_tensor_default_4, _param_constant3)  {}\n",
      "call_function  quantize_per_tensor_default_5    quantized_decomposed.quantize_per_tensor.default    (conv2d_1, 1.0, 0, -128, 127, torch.int8)                                             {}\n",
      "call_function  dequantize_per_tensor_default_5  quantized_decomposed.dequantize_per_tensor.default  (quantize_per_tensor_default_5, 1.0, 0, -128, 127, torch.int8)                        {}\n",
      "call_function  leaky_relu_1                     aten.leaky_relu.default                             (dequantize_per_tensor_default_5,)                                                    {}\n",
      "call_function  max_pool2d_1                     aten.max_pool2d.default                             (leaky_relu_1, [2, 2], [2, 2])                                                        {}\n",
      "call_function  flatten                          aten.flatten.using_ints                             (max_pool2d_1, 1)                                                                     {}\n",
      "call_function  quantize_per_tensor_default_6    quantized_decomposed.quantize_per_tensor.default    (flatten, 1.0, 0, -128, 127, torch.int8)                                              {}\n",
      "call_function  dequantize_per_tensor_default_6  quantized_decomposed.dequantize_per_tensor.default  (quantize_per_tensor_default_6, 1.0, 0, -128, 127, torch.int8)                        {}\n",
      "get_attr       _frozen_param2                   _frozen_param2                                      ()                                                                                    {}\n",
      "call_function  dequantize_per_tensor_default_7  quantized_decomposed.dequantize_per_tensor.default  (_frozen_param2, 1.0, 0, -127, 127, torch.int8)                                       {}\n",
      "get_attr       _param_constant5                 fc_0_bias                                           ()                                                                                    {}\n",
      "call_function  linear                           aten.linear.default                                 (dequantize_per_tensor_default_6, dequantize_per_tensor_default_7, _param_constant5)  {}\n",
      "call_function  quantize_per_tensor_default_8    quantized_decomposed.quantize_per_tensor.default    (linear, 1.0, 0, -128, 127, torch.int8)                                               {}\n",
      "call_function  dequantize_per_tensor_default_8  quantized_decomposed.dequantize_per_tensor.default  (quantize_per_tensor_default_8, 1.0, 0, -128, 127, torch.int8)                        {}\n",
      "call_function  leaky_relu_2                     aten.leaky_relu.default                             (dequantize_per_tensor_default_8,)                                                    {}\n",
      "call_function  dropout                          aten.dropout.default                                (leaky_relu_2, 0.1, True)                                                             {}\n",
      "output         output                           output                                              ([dropout],)                                                                          {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/neverorfrog/.miniconda3/envs/executorch/lib/python3.10/site-packages/torch/ao/quantization/observer.py:1272: UserWarning: must run observer before calling calculate_qparams.                                    Returning default scale and zero point \n",
      "  warnings.warn(\n",
      "/home/neverorfrog/.miniconda3/envs/executorch/lib/python3.10/site-packages/torch/ao/quantization/utils.py:339: UserWarning: must run observer before calling calculate_qparams. Returning default values.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from torch.ao.quantization.quantize_pt2e import convert_pt2e, prepare_pt2e\n",
    "from torch.ao.quantization.quantizer.xnnpack_quantizer import (\n",
    "    get_symmetric_quantization_config,\n",
    "    XNNPACKQuantizer,\n",
    ")\n",
    "\n",
    "quantizer = XNNPACKQuantizer().set_global(get_symmetric_quantization_config())\n",
    "prepared_graph = prepare_pt2e(pre_autograd_aten_dialect, quantizer)\n",
    "converted_graph = convert_pt2e(prepared_graph)\n",
    "print(\"Quantized Graph\")\n",
    "converted_graph.graph.print_tabular()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) Core ATen Dialect\n",
    "- [export()](https://pytorch.org/docs/2.1/export.html#torch.export.export) takes an arbitrary Python callable (an nn.Module, a function or a method) and produces a traced graph representing only the Tensor computation of the function in an Ahead-of-Time (AOT) fashion, which can subsequently be executed with different outputs or serialized. \n",
    "- The traced graph does three things \n",
    "    1) produces a normalized operator set consisting only of functional Core ATen Operator Set and user specified custom operators\n",
    "    2) has eliminated all Python control flow and data structures (except for certain conditions)\n",
    "    3) has the set of shape constraints needed to show that this normalization and control flow elimination is sound for a future input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ATen Dialect Graph\n",
      "opcode         name                       target                                args                                                                 kwargs\n",
      "-------------  -------------------------  ------------------------------------  -------------------------------------------------------------------  --------\n",
      "placeholder    arg0_1                     arg0_1                                ()                                                                   {}\n",
      "placeholder    arg1_1                     arg1_1                                ()                                                                   {}\n",
      "placeholder    arg2_1                     arg2_1                                ()                                                                   {}\n",
      "placeholder    arg3_1                     arg3_1                                ()                                                                   {}\n",
      "placeholder    arg4_1                     arg4_1                                ()                                                                   {}\n",
      "placeholder    arg5_1                     arg5_1                                ()                                                                   {}\n",
      "placeholder    arg6_1                     arg6_1                                ()                                                                   {}\n",
      "call_function  convolution                aten.convolution.default              (arg6_1, arg0_1, arg1_1, [1, 1], [0, 0], [1, 1], False, [0, 0], 1)   {}\n",
      "call_function  leaky_relu                 aten.leaky_relu.default               (convolution,)                                                       {}\n",
      "call_function  max_pool2d_with_indices    aten.max_pool2d_with_indices.default  (leaky_relu, [2, 2], [2, 2])                                         {}\n",
      "call_function  getitem                    <built-in function getitem>           (max_pool2d_with_indices, 0)                                         {}\n",
      "call_function  convolution_1              aten.convolution.default              (getitem, arg2_1, arg3_1, [1, 1], [0, 0], [1, 1], False, [0, 0], 1)  {}\n",
      "call_function  leaky_relu_1               aten.leaky_relu.default               (convolution_1,)                                                     {}\n",
      "call_function  max_pool2d_with_indices_1  aten.max_pool2d_with_indices.default  (leaky_relu_1, [2, 2], [2, 2])                                       {}\n",
      "call_function  getitem_2                  <built-in function getitem>           (max_pool2d_with_indices_1, 0)                                       {}\n",
      "call_function  view                       aten.view.default                     (getitem_2, [1, 320])                                                {}\n",
      "call_function  t                          aten.t.default                        (arg4_1,)                                                            {}\n",
      "call_function  addmm                      aten.addmm.default                    (arg5_1, view, t)                                                    {}\n",
      "call_function  leaky_relu_2               aten.leaky_relu.default               (addmm,)                                                             {}\n",
      "call_function  native_dropout             aten.native_dropout.default           (leaky_relu_2, 0.1, True)                                            {}\n",
      "call_function  getitem_4                  <built-in function getitem>           (native_dropout, 0)                                                  {}\n",
      "output         output                     output                                ((getitem_4,),)                                                      {}\n"
     ]
    }
   ],
   "source": [
    "from torch.export import export, ExportedProgram\n",
    "aten_dialect: ExportedProgram = export(pre_autograd_aten_dialect, m.example_args)\n",
    "print(\"ATen Dialect Graph\")\n",
    "aten_dialect.graph.print_tabular()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4) Edge Dialect\n",
    "- to_edge() returns an EdgeProgramManager object, which contains the exported programs which will be placed on this device\n",
    "    - DType specialization\n",
    "    - Scalar to tensor conversion\n",
    "    - Converting all ops to the executorch.exir.dialects.edge namespace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Edge Dialect Graph\n",
      "opcode         name                                    target                                                                                                                                                                                                                                      args                                                                 kwargs\n",
      "-------------  --------------------------------------  ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------  -------------------------------------------------------------------  --------\n",
      "placeholder    arg0_1                                  arg0_1                                                                                                                                                                                                                                      ()                                                                   {}\n",
      "placeholder    arg1_1                                  arg1_1                                                                                                                                                                                                                                      ()                                                                   {}\n",
      "placeholder    arg2_1                                  arg2_1                                                                                                                                                                                                                                      ()                                                                   {}\n",
      "placeholder    arg3_1                                  arg3_1                                                                                                                                                                                                                                      ()                                                                   {}\n",
      "placeholder    arg4_1                                  arg4_1                                                                                                                                                                                                                                      ()                                                                   {}\n",
      "placeholder    arg5_1                                  arg5_1                                                                                                                                                                                                                                      ()                                                                   {}\n",
      "placeholder    arg6_1                                  arg6_1                                                                                                                                                                                                                                      ()                                                                   {}\n",
      "call_function  aten_convolution_default                <EdgeOpOverload: aten.convolution.default>: schema = aten::convolution(Tensor input, Tensor weight, Tensor? bias, SymInt[] stride, SymInt[] padding, SymInt[] dilation, bool transposed, SymInt[] output_padding, SymInt groups) -> Tensor  (arg6_1, arg0_1, arg1_1, [1, 1], [0, 0], [1, 1], False, [0, 0], 1)   {}\n",
      "call_function  aten_leaky_relu_default                 <EdgeOpOverload: aten.leaky_relu.default>: schema = aten::leaky_relu(Tensor self, Scalar negative_slope=0.01) -> Tensor                                                                                                                     (aten_convolution_default,)                                          {}\n",
      "call_function  aten_max_pool2d_with_indices_default    <EdgeOpOverload: aten.max_pool2d_with_indices.default>: schema = aten::max_pool2d_with_indices(Tensor self, int[2] kernel_size, int[2] stride=[], int[2] padding=0, int[2] dilation=1, bool ceil_mode=False) -> (Tensor, Tensor)            (aten_leaky_relu_default, [2, 2], [2, 2])                            {}\n",
      "call_function  getitem                                 <built-in function getitem>                                                                                                                                                                                                                 (aten_max_pool2d_with_indices_default, 0)                            {}\n",
      "call_function  aten_convolution_default_1              <EdgeOpOverload: aten.convolution.default>: schema = aten::convolution(Tensor input, Tensor weight, Tensor? bias, SymInt[] stride, SymInt[] padding, SymInt[] dilation, bool transposed, SymInt[] output_padding, SymInt groups) -> Tensor  (getitem, arg2_1, arg3_1, [1, 1], [0, 0], [1, 1], False, [0, 0], 1)  {}\n",
      "call_function  aten_leaky_relu_default_1               <EdgeOpOverload: aten.leaky_relu.default>: schema = aten::leaky_relu(Tensor self, Scalar negative_slope=0.01) -> Tensor                                                                                                                     (aten_convolution_default_1,)                                        {}\n",
      "call_function  aten_max_pool2d_with_indices_default_1  <EdgeOpOverload: aten.max_pool2d_with_indices.default>: schema = aten::max_pool2d_with_indices(Tensor self, int[2] kernel_size, int[2] stride=[], int[2] padding=0, int[2] dilation=1, bool ceil_mode=False) -> (Tensor, Tensor)            (aten_leaky_relu_default_1, [2, 2], [2, 2])                          {}\n",
      "call_function  getitem_1                               <built-in function getitem>                                                                                                                                                                                                                 (aten_max_pool2d_with_indices_default_1, 0)                          {}\n",
      "call_function  aten_view_copy_default                  <EdgeOpOverload: aten.view_copy.default>: schema = aten::view_copy(Tensor self, SymInt[] size) -> Tensor                                                                                                                                    (getitem_1, [1, 320])                                                {}\n",
      "call_function  aten_permute_copy_default               <EdgeOpOverload: aten.permute_copy.default>: schema = aten::permute_copy(Tensor self, int[] dims) -> Tensor                                                                                                                                 (arg4_1, [1, 0])                                                     {}\n",
      "call_function  aten_addmm_default                      <EdgeOpOverload: aten.addmm.default>: schema = aten::addmm(Tensor self, Tensor mat1, Tensor mat2, *, Scalar beta=1, Scalar alpha=1) -> Tensor                                                                                               (arg5_1, aten_view_copy_default, aten_permute_copy_default)          {}\n",
      "call_function  aten_leaky_relu_default_2               <EdgeOpOverload: aten.leaky_relu.default>: schema = aten::leaky_relu(Tensor self, Scalar negative_slope=0.01) -> Tensor                                                                                                                     (aten_addmm_default,)                                                {}\n",
      "call_function  aten_native_dropout_default             <EdgeOpOverload: aten.native_dropout.default>: schema = aten::native_dropout(Tensor input, float p, bool? train) -> (Tensor, Tensor)                                                                                                        (aten_leaky_relu_default_2, 0.1, True)                               {}\n",
      "call_function  getitem_2                               <built-in function getitem>                                                                                                                                                                                                                 (aten_native_dropout_default, 0)                                     {}\n",
      "output         output                                  output                                                                                                                                                                                                                                      ((getitem_2,),)                                                      {}\n"
     ]
    }
   ],
   "source": [
    "from executorch.exir import EdgeProgramManager, to_edge\n",
    "edge_program: EdgeProgramManager = to_edge(aten_dialect)\n",
    "print(\"Edge Dialect Graph\")\n",
    "to_be_lowered_module = edge_program.exported_program()\n",
    "to_be_lowered_module.graph.print_tabular()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Delegate to a Backend (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from executorch.exir.backend.backend_api import LoweredBackendModule, to_backend\n",
    "from executorch.exir.backend.test.backend_with_compiler_demo import (  # noqa\n",
    "    BackendWithCompilerDemo,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Executorch Programs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ExecuTorch Dialect\n",
      "opcode         name                                    target                              args                                                                 kwargs\n",
      "-------------  --------------------------------------  ----------------------------------  -------------------------------------------------------------------  ------------------------------------\n",
      "placeholder    arg0_1                                  arg0_1                              ()                                                                   {}\n",
      "placeholder    arg1_1                                  arg1_1                              ()                                                                   {}\n",
      "placeholder    arg2_1                                  arg2_1                              ()                                                                   {}\n",
      "placeholder    arg3_1                                  arg3_1                              ()                                                                   {}\n",
      "placeholder    arg4_1                                  arg4_1                              ()                                                                   {}\n",
      "placeholder    arg5_1                                  arg5_1                              ()                                                                   {}\n",
      "placeholder    arg6_1                                  arg6_1                              ()                                                                   {}\n",
      "call_function  alloc                                   <function alloc at 0x7eae114dbd90>  (((1, 10, 24, 24), torch.float32),)                                  {}\n",
      "call_function  aten_convolution_default                aten.convolution.out                (arg6_1, arg0_1, arg1_1, [1, 1], [0, 0], [1, 1], False, [0, 0], 1)   {'out': alloc}\n",
      "call_function  alloc_1                                 <function alloc at 0x7eae114dbd90>  (((1, 10, 24, 24), torch.float32),)                                  {}\n",
      "call_function  aten_leaky_relu_default                 aten.leaky_relu.out                 (aten_convolution_default,)                                          {'out': alloc_1}\n",
      "call_function  alloc_2                                 <function alloc at 0x7eae114dbd90>  (((1, 10, 12, 12), torch.float32),)                                  {}\n",
      "call_function  alloc_3                                 <function alloc at 0x7eae114dbd90>  (((1, 10, 12, 12), torch.int64),)                                    {}\n",
      "call_function  aten_max_pool2d_with_indices_default    aten.max_pool2d_with_indices.out    (aten_leaky_relu_default, [2, 2], [2, 2])                            {'out': alloc_2, 'indices': alloc_3}\n",
      "call_function  getitem                                 <built-in function getitem>         (aten_max_pool2d_with_indices_default, 0)                            {}\n",
      "call_function  alloc_4                                 <function alloc at 0x7eae114dbd90>  (((1, 20, 8, 8), torch.float32),)                                    {}\n",
      "call_function  aten_convolution_default_1              aten.convolution.out                (getitem, arg2_1, arg3_1, [1, 1], [0, 0], [1, 1], False, [0, 0], 1)  {'out': alloc_4}\n",
      "call_function  alloc_5                                 <function alloc at 0x7eae114dbd90>  (((1, 20, 8, 8), torch.float32),)                                    {}\n",
      "call_function  aten_leaky_relu_default_1               aten.leaky_relu.out                 (aten_convolution_default_1,)                                        {'out': alloc_5}\n",
      "call_function  alloc_6                                 <function alloc at 0x7eae114dbd90>  (((1, 20, 4, 4), torch.float32),)                                    {}\n",
      "call_function  alloc_7                                 <function alloc at 0x7eae114dbd90>  (((1, 20, 4, 4), torch.int64),)                                      {}\n",
      "call_function  aten_max_pool2d_with_indices_default_1  aten.max_pool2d_with_indices.out    (aten_leaky_relu_default_1, [2, 2], [2, 2])                          {'out': alloc_6, 'indices': alloc_7}\n",
      "call_function  getitem_1                               <built-in function getitem>         (aten_max_pool2d_with_indices_default_1, 0)                          {}\n",
      "call_function  alloc_8                                 <function alloc at 0x7eae114dbd90>  (((1, 320), torch.float32),)                                         {}\n",
      "call_function  aten_view_copy_default                  aten.view_copy.out                  (getitem_1, [1, 320])                                                {'out': alloc_8}\n",
      "call_function  alloc_9                                 <function alloc at 0x7eae114dbd90>  (((320, 10), torch.float32),)                                        {}\n",
      "call_function  aten_permute_copy_default               aten.permute_copy.out               (arg4_1, [1, 0])                                                     {'out': alloc_9}\n",
      "call_function  alloc_10                                <function alloc at 0x7eae114dbd90>  (((1, 10), torch.float32),)                                          {}\n",
      "call_function  aten_addmm_default                      aten.addmm.out                      (arg5_1, aten_view_copy_default, aten_permute_copy_default)          {'out': alloc_10}\n",
      "call_function  alloc_11                                <function alloc at 0x7eae114dbd90>  (((1, 10), torch.float32),)                                          {}\n",
      "call_function  aten_leaky_relu_default_2               aten.leaky_relu.out                 (aten_addmm_default,)                                                {'out': alloc_11}\n",
      "call_function  alloc_12                                <function alloc at 0x7eae114dbd90>  (((1, 10), torch.float32),)                                          {}\n",
      "call_function  alloc_13                                <function alloc at 0x7eae114dbd90>  (((1, 10), torch.bool),)                                             {}\n",
      "call_function  aten_native_dropout_default             aten.native_dropout.out             (aten_leaky_relu_default_2, 0.1, True)                               {'out0': alloc_12, 'out1': alloc_13}\n",
      "call_function  getitem_2                               <built-in function getitem>         (aten_native_dropout_default, 0)                                     {}\n",
      "output         output_1                                output                              ((getitem_2,),)                                                      {}\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from executorch.exir import ExecutorchBackendConfig, ExecutorchProgramManager\n",
    "from executorch.exir.passes import MemoryPlanningPass\n",
    "\n",
    "executorch_program: ExecutorchProgramManager = edge_program.to_executorch(\n",
    "    ExecutorchBackendConfig(\n",
    "        passes=[],  # User-defined passes\n",
    "        memory_planning_pass=MemoryPlanningPass(\n",
    "            \"greedy\"\n",
    "        ),  # Default memory planning pass\n",
    "    )\n",
    ")\n",
    "\n",
    "print(\"ExecuTorch Dialect\")\n",
    "print(executorch_program.exported_program().graph.print_tabular())\n",
    "\n",
    "\n",
    "with open(f\"{projroot}/models/executorch/model.pte\", \"wb\") as file:\n",
    "    file.write(executorch_program.buffer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "machine-learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
