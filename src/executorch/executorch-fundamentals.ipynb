{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "from datamodules.mnist import MnistDataset\n",
    "from core.trainer import Trainer\n",
    "from models import CNN\n",
    "from models import MNIST_CONFIG as config\n",
    "import torch\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from core import project_root\n",
    "projroot = project_root()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATA SAVED!\n",
      "N Examples: 54000\n",
      "N Classes: 10\n",
      "Classes: [0 1 2 3 4 5 6 7 8 9]\n",
      " - Class 0: 5343 (9.894444444444444)\n",
      " - Class 1: 6036 (11.177777777777779)\n",
      " - Class 2: 5348 (9.903703703703703)\n",
      " - Class 3: 5583 (10.338888888888889)\n",
      " - Class 4: 5249 (9.720370370370372)\n",
      " - Class 5: 4859 (8.998148148148148)\n",
      " - Class 6: 5335 (9.87962962962963)\n",
      " - Class 7: 5664 (10.488888888888889)\n",
      " - Class 8: 5234 (9.692592592592593)\n",
      " - Class 9: 5349 (9.905555555555555)\n",
      "MODEL LOADED!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x70ab5c275ff0>]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = MnistDataset(tobeloaded=False, params=config.DATA_PARAMS)\n",
    "dataset.summarize()\n",
    "model = CNN(\"mnist\", num_classes=10)\n",
    "trainer = Trainer(params=config.TRAIN_PARAMS)\n",
    "model.load(\"mnist\")\n",
    "# trainer.fit(model,dataset)\n",
    "plt.plot(model.test_scores, label=f'mnist - test scores')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install\n",
    "\n",
    "### [Getting Started](https://pytorch.org/executorch/stable/getting-started-setup.html)\n",
    "### [Building with CMake](https://pytorch.org/executorch/stable/runtime-build-and-cross-compilation.html)\n",
    "\n",
    "# Toy Example \n",
    "### [PyTorch Source](https://pytorch.org/executorch/stable/tutorials/export-to-executorch-tutorial.html)\n",
    "\n",
    "![picture 1](images/workflow.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.2054e-03,  7.8042e-03,  1.5622e+00,  2.0319e-01, -2.5658e-03,\n",
       "         -8.9394e-05,  9.3103e-01, -5.0285e-03, -1.3109e-02,  4.1132e-01]],\n",
       "       grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class FullyConnected(torch.nn.Module):\n",
    "    #Fully Connected layers    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        fc_dims = [4,1]\n",
    "        self.activation = nn.ReLU()\n",
    "        self.example_args = (torch.randn(1, 4),)\n",
    "        fc_layers = []\n",
    "        for i in range(len(fc_dims)-1):\n",
    "            fc_layers.append(nn.Linear(fc_dims[i],fc_dims[i+1],bias=True))\n",
    "            fc_layers.append(self.activation)\n",
    "        self.fc = nn.Sequential(*fc_layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc(x)\n",
    "    \n",
    "class Add(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.example_args = (torch.randn(1, 4), torch.randn(1, 4))\n",
    "        \n",
    "    def forward(self,x,y):\n",
    "        return x + y\n",
    "    \n",
    "# m = FullyConnected()\n",
    "m = CNN(\"mnist\",num_classes=10)\n",
    "m(*m.example_args)\n",
    "# m.load(\"mnist\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Pre-Autograd ATen Dialect\n",
    "    - Trace a module before any pre-autograd decomposition is run. Later this API will be changed like stated [here](https://github.com/pytorch/executorch/issues/290)\n",
    "        - Tracing means converting a PyTorch model into a more efficient, serialized format suitable for deployment in production or environments where Python might not be available.\n",
    "    - The result is still nn.Module but only with ATen operations, which are safe for eager mode training\n",
    "        - Eager mode training means we are still in an imperative fashion\n",
    "    - We will print the graph, represented through [Torch Fx](https://pytorch.org/docs/stable/fx.html#module-torch.fx), in a table to explicitly represent inputs, operations and outputs (more info [here](https://pytorch.org/docs/stable/fx.html#torch.fx.Node))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-Autograd ATen Dialect Graph\n",
      "opcode         name              target                   args                                              kwargs\n",
      "-------------  ----------------  -----------------------  ------------------------------------------------  -------------------------------------------------------------------------------\n",
      "placeholder    arg0_1            arg0                     ()                                                {}\n",
      "call_function  to                aten.to.dtype            (arg0_1, torch.float32)                           {}\n",
      "call_function  to_1              aten.to.dtype_layout     (to,)                                             {'dtype': torch.float32, 'layout': torch.strided, 'device': device(type='cpu')}\n",
      "get_attr       _param_constant0  conv_0_weight            ()                                                {}\n",
      "get_attr       _param_constant1  conv_0_bias              ()                                                {}\n",
      "call_function  conv2d            aten.conv2d.default      (to_1, _param_constant0, _param_constant1)        {}\n",
      "call_function  leaky_relu        aten.leaky_relu.default  (conv2d,)                                         {}\n",
      "call_function  max_pool2d        aten.max_pool2d.default  (leaky_relu, [2, 2], [2, 2])                      {}\n",
      "get_attr       _param_constant2  conv_3_weight            ()                                                {}\n",
      "get_attr       _param_constant3  conv_3_bias              ()                                                {}\n",
      "call_function  conv2d_1          aten.conv2d.default      (max_pool2d, _param_constant2, _param_constant3)  {}\n",
      "call_function  leaky_relu_1      aten.leaky_relu.default  (conv2d_1,)                                       {}\n",
      "call_function  max_pool2d_1      aten.max_pool2d.default  (leaky_relu_1, [2, 2], [2, 2])                    {}\n",
      "call_function  flatten           aten.flatten.using_ints  (max_pool2d_1, 1)                                 {}\n",
      "get_attr       _param_constant4  fc_0_weight              ()                                                {}\n",
      "get_attr       _param_constant5  fc_0_bias                ()                                                {}\n",
      "call_function  linear            aten.linear.default      (flatten, _param_constant4, _param_constant5)     {}\n",
      "call_function  leaky_relu_2      aten.leaky_relu.default  (linear,)                                         {}\n",
      "call_function  dropout           aten.dropout.default     (leaky_relu_2, 0.1, True)                         {}\n",
      "output         output            output                   ([dropout],)                                      {}\n"
     ]
    }
   ],
   "source": [
    "from torch._export import capture_pre_autograd_graph\n",
    "pre_autograd_aten_dialect = capture_pre_autograd_graph(m, m.example_args)\n",
    "print(\"Pre-Autograd ATen Dialect Graph\")\n",
    "pre_autograd_aten_dialect.graph.print_tabular()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Quantization (optional)\n",
    "    - Lower the precision, maintaining the accuracy high enough\n",
    "    - Goal is to enhance memory and computational efficiency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantized Graph\n",
      "opcode         name                             target                                              args                                                                                  kwargs\n",
      "-------------  -------------------------------  --------------------------------------------------  ------------------------------------------------------------------------------------  -------------------------------------------------------------------------------\n",
      "placeholder    arg0_1                           arg0                                                ()                                                                                    {}\n",
      "call_function  to                               aten.to.dtype                                       (arg0_1, torch.float32)                                                               {}\n",
      "call_function  to_1                             aten.to.dtype_layout                                (to,)                                                                                 {'dtype': torch.float32, 'layout': torch.strided, 'device': device(type='cpu')}\n",
      "call_function  quantize_per_tensor_default      quantized_decomposed.quantize_per_tensor.default    (to_1, 1.0, 0, -128, 127, torch.int8)                                                 {}\n",
      "call_function  dequantize_per_tensor_default    quantized_decomposed.dequantize_per_tensor.default  (quantize_per_tensor_default, 1.0, 0, -128, 127, torch.int8)                          {}\n",
      "get_attr       _frozen_param0                   _frozen_param0                                      ()                                                                                    {}\n",
      "call_function  dequantize_per_tensor_default_1  quantized_decomposed.dequantize_per_tensor.default  (_frozen_param0, 1.0, 0, -127, 127, torch.int8)                                       {}\n",
      "get_attr       _param_constant1                 conv_0_bias                                         ()                                                                                    {}\n",
      "call_function  conv2d                           aten.conv2d.default                                 (dequantize_per_tensor_default, dequantize_per_tensor_default_1, _param_constant1)    {}\n",
      "call_function  quantize_per_tensor_default_2    quantized_decomposed.quantize_per_tensor.default    (conv2d, 1.0, 0, -128, 127, torch.int8)                                               {}\n",
      "call_function  dequantize_per_tensor_default_2  quantized_decomposed.dequantize_per_tensor.default  (quantize_per_tensor_default_2, 1.0, 0, -128, 127, torch.int8)                        {}\n",
      "call_function  leaky_relu                       aten.leaky_relu.default                             (dequantize_per_tensor_default_2,)                                                    {}\n",
      "call_function  max_pool2d                       aten.max_pool2d.default                             (leaky_relu, [2, 2], [2, 2])                                                          {}\n",
      "call_function  quantize_per_tensor_default_3    quantized_decomposed.quantize_per_tensor.default    (max_pool2d, 1.0, 0, -128, 127, torch.int8)                                           {}\n",
      "call_function  dequantize_per_tensor_default_3  quantized_decomposed.dequantize_per_tensor.default  (quantize_per_tensor_default_3, 1.0, 0, -128, 127, torch.int8)                        {}\n",
      "get_attr       _frozen_param1                   _frozen_param1                                      ()                                                                                    {}\n",
      "call_function  dequantize_per_tensor_default_4  quantized_decomposed.dequantize_per_tensor.default  (_frozen_param1, 1.0, 0, -127, 127, torch.int8)                                       {}\n",
      "get_attr       _param_constant3                 conv_3_bias                                         ()                                                                                    {}\n",
      "call_function  conv2d_1                         aten.conv2d.default                                 (dequantize_per_tensor_default_3, dequantize_per_tensor_default_4, _param_constant3)  {}\n",
      "call_function  quantize_per_tensor_default_5    quantized_decomposed.quantize_per_tensor.default    (conv2d_1, 1.0, 0, -128, 127, torch.int8)                                             {}\n",
      "call_function  dequantize_per_tensor_default_5  quantized_decomposed.dequantize_per_tensor.default  (quantize_per_tensor_default_5, 1.0, 0, -128, 127, torch.int8)                        {}\n",
      "call_function  leaky_relu_1                     aten.leaky_relu.default                             (dequantize_per_tensor_default_5,)                                                    {}\n",
      "call_function  max_pool2d_1                     aten.max_pool2d.default                             (leaky_relu_1, [2, 2], [2, 2])                                                        {}\n",
      "call_function  flatten                          aten.flatten.using_ints                             (max_pool2d_1, 1)                                                                     {}\n",
      "call_function  quantize_per_tensor_default_6    quantized_decomposed.quantize_per_tensor.default    (flatten, 1.0, 0, -128, 127, torch.int8)                                              {}\n",
      "call_function  dequantize_per_tensor_default_6  quantized_decomposed.dequantize_per_tensor.default  (quantize_per_tensor_default_6, 1.0, 0, -128, 127, torch.int8)                        {}\n",
      "get_attr       _frozen_param2                   _frozen_param2                                      ()                                                                                    {}\n",
      "call_function  dequantize_per_tensor_default_7  quantized_decomposed.dequantize_per_tensor.default  (_frozen_param2, 1.0, 0, -127, 127, torch.int8)                                       {}\n",
      "get_attr       _param_constant5                 fc_0_bias                                           ()                                                                                    {}\n",
      "call_function  linear                           aten.linear.default                                 (dequantize_per_tensor_default_6, dequantize_per_tensor_default_7, _param_constant5)  {}\n",
      "call_function  quantize_per_tensor_default_8    quantized_decomposed.quantize_per_tensor.default    (linear, 1.0, 0, -128, 127, torch.int8)                                               {}\n",
      "call_function  dequantize_per_tensor_default_8  quantized_decomposed.dequantize_per_tensor.default  (quantize_per_tensor_default_8, 1.0, 0, -128, 127, torch.int8)                        {}\n",
      "call_function  leaky_relu_2                     aten.leaky_relu.default                             (dequantize_per_tensor_default_8,)                                                    {}\n",
      "call_function  dropout                          aten.dropout.default                                (leaky_relu_2, 0.1, True)                                                             {}\n",
      "output         output                           output                                              ([dropout],)                                                                          {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/neverorfrog/.miniconda3/envs/executorch/lib/python3.10/site-packages/torch/ao/quantization/observer.py:1272: UserWarning: must run observer before calling calculate_qparams.                                    Returning default scale and zero point \n",
      "  warnings.warn(\n",
      "/home/neverorfrog/.miniconda3/envs/executorch/lib/python3.10/site-packages/torch/ao/quantization/utils.py:339: UserWarning: must run observer before calling calculate_qparams. Returning default values.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from torch.ao.quantization.quantize_pt2e import convert_pt2e, prepare_pt2e\n",
    "from torch.ao.quantization.quantizer.xnnpack_quantizer import (\n",
    "    get_symmetric_quantization_config,\n",
    "    XNNPACKQuantizer,\n",
    ")\n",
    "\n",
    "quantizer = XNNPACKQuantizer().set_global(get_symmetric_quantization_config())\n",
    "prepared_graph = prepare_pt2e(pre_autograd_aten_dialect, quantizer)\n",
    "converted_graph = convert_pt2e(prepared_graph)\n",
    "print(\"Quantized Graph\")\n",
    "converted_graph.graph.print_tabular()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) Core ATen Dialect\n",
    "- [export()](https://pytorch.org/docs/2.1/export.html#torch.export.export) takes an arbitrary Python callable (an nn.Module, a function or a method) and produces a traced graph representing only the Tensor computation of the function in an Ahead-of-Time (AOT) fashion, which can subsequently be executed with different outputs or serialized. \n",
    "- The traced graph does three things \n",
    "    1) produces a normalized operator set consisting only of functional Core ATen Operator Set and user specified custom operators\n",
    "    2) has eliminated all Python control flow and data structures (except for certain conditions)\n",
    "    3) has the set of shape constraints needed to show that this normalization and control flow elimination is sound for a future input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ATen Dialect Graph\n",
      "opcode         name                       target                                args                                                                 kwargs\n",
      "-------------  -------------------------  ------------------------------------  -------------------------------------------------------------------  --------\n",
      "placeholder    arg0_1                     arg0_1                                ()                                                                   {}\n",
      "placeholder    arg1_1                     arg1_1                                ()                                                                   {}\n",
      "placeholder    arg2_1                     arg2_1                                ()                                                                   {}\n",
      "placeholder    arg3_1                     arg3_1                                ()                                                                   {}\n",
      "placeholder    arg4_1                     arg4_1                                ()                                                                   {}\n",
      "placeholder    arg5_1                     arg5_1                                ()                                                                   {}\n",
      "placeholder    arg6_1                     arg6_1                                ()                                                                   {}\n",
      "call_function  convolution                aten.convolution.default              (arg6_1, arg0_1, arg1_1, [1, 1], [0, 0], [1, 1], False, [0, 0], 1)   {}\n",
      "call_function  leaky_relu                 aten.leaky_relu.default               (convolution,)                                                       {}\n",
      "call_function  max_pool2d_with_indices    aten.max_pool2d_with_indices.default  (leaky_relu, [2, 2], [2, 2])                                         {}\n",
      "call_function  getitem                    <built-in function getitem>           (max_pool2d_with_indices, 0)                                         {}\n",
      "call_function  convolution_1              aten.convolution.default              (getitem, arg2_1, arg3_1, [1, 1], [0, 0], [1, 1], False, [0, 0], 1)  {}\n",
      "call_function  leaky_relu_1               aten.leaky_relu.default               (convolution_1,)                                                     {}\n",
      "call_function  max_pool2d_with_indices_1  aten.max_pool2d_with_indices.default  (leaky_relu_1, [2, 2], [2, 2])                                       {}\n",
      "call_function  getitem_2                  <built-in function getitem>           (max_pool2d_with_indices_1, 0)                                       {}\n",
      "call_function  view                       aten.view.default                     (getitem_2, [1, 320])                                                {}\n",
      "call_function  t                          aten.t.default                        (arg4_1,)                                                            {}\n",
      "call_function  addmm                      aten.addmm.default                    (arg5_1, view, t)                                                    {}\n",
      "call_function  leaky_relu_2               aten.leaky_relu.default               (addmm,)                                                             {}\n",
      "call_function  native_dropout             aten.native_dropout.default           (leaky_relu_2, 0.1, True)                                            {}\n",
      "call_function  getitem_4                  <built-in function getitem>           (native_dropout, 0)                                                  {}\n",
      "output         output                     output                                ((getitem_4,),)                                                      {}\n"
     ]
    }
   ],
   "source": [
    "from torch.export import export, ExportedProgram\n",
    "aten_dialect: ExportedProgram = export(pre_autograd_aten_dialect, m.example_args)\n",
    "print(\"ATen Dialect Graph\")\n",
    "aten_dialect.graph.print_tabular()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4) Edge Dialect\n",
    "- to_edge() returns an EdgeProgramManager object, which contains the exported programs which will be placed on this device\n",
    "    - DType specialization\n",
    "    - Scalar to tensor conversion\n",
    "    - Converting all ops to the executorch.exir.dialects.edge namespace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Edge Dialect Graph\n",
      "opcode         name                                    target                                                                                                                                                                                                                                      args                                                                 kwargs\n",
      "-------------  --------------------------------------  ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------  -------------------------------------------------------------------  --------\n",
      "placeholder    arg0_1                                  arg0_1                                                                                                                                                                                                                                      ()                                                                   {}\n",
      "placeholder    arg1_1                                  arg1_1                                                                                                                                                                                                                                      ()                                                                   {}\n",
      "placeholder    arg2_1                                  arg2_1                                                                                                                                                                                                                                      ()                                                                   {}\n",
      "placeholder    arg3_1                                  arg3_1                                                                                                                                                                                                                                      ()                                                                   {}\n",
      "placeholder    arg4_1                                  arg4_1                                                                                                                                                                                                                                      ()                                                                   {}\n",
      "placeholder    arg5_1                                  arg5_1                                                                                                                                                                                                                                      ()                                                                   {}\n",
      "placeholder    arg6_1                                  arg6_1                                                                                                                                                                                                                                      ()                                                                   {}\n",
      "call_function  aten_convolution_default                <EdgeOpOverload: aten.convolution.default>: schema = aten::convolution(Tensor input, Tensor weight, Tensor? bias, SymInt[] stride, SymInt[] padding, SymInt[] dilation, bool transposed, SymInt[] output_padding, SymInt groups) -> Tensor  (arg6_1, arg0_1, arg1_1, [1, 1], [0, 0], [1, 1], False, [0, 0], 1)   {}\n",
      "call_function  aten_leaky_relu_default                 <EdgeOpOverload: aten.leaky_relu.default>: schema = aten::leaky_relu(Tensor self, Scalar negative_slope=0.01) -> Tensor                                                                                                                     (aten_convolution_default,)                                          {}\n",
      "call_function  aten_max_pool2d_with_indices_default    <EdgeOpOverload: aten.max_pool2d_with_indices.default>: schema = aten::max_pool2d_with_indices(Tensor self, int[2] kernel_size, int[2] stride=[], int[2] padding=0, int[2] dilation=1, bool ceil_mode=False) -> (Tensor, Tensor)            (aten_leaky_relu_default, [2, 2], [2, 2])                            {}\n",
      "call_function  getitem                                 <built-in function getitem>                                                                                                                                                                                                                 (aten_max_pool2d_with_indices_default, 0)                            {}\n",
      "call_function  aten_convolution_default_1              <EdgeOpOverload: aten.convolution.default>: schema = aten::convolution(Tensor input, Tensor weight, Tensor? bias, SymInt[] stride, SymInt[] padding, SymInt[] dilation, bool transposed, SymInt[] output_padding, SymInt groups) -> Tensor  (getitem, arg2_1, arg3_1, [1, 1], [0, 0], [1, 1], False, [0, 0], 1)  {}\n",
      "call_function  aten_leaky_relu_default_1               <EdgeOpOverload: aten.leaky_relu.default>: schema = aten::leaky_relu(Tensor self, Scalar negative_slope=0.01) -> Tensor                                                                                                                     (aten_convolution_default_1,)                                        {}\n",
      "call_function  aten_max_pool2d_with_indices_default_1  <EdgeOpOverload: aten.max_pool2d_with_indices.default>: schema = aten::max_pool2d_with_indices(Tensor self, int[2] kernel_size, int[2] stride=[], int[2] padding=0, int[2] dilation=1, bool ceil_mode=False) -> (Tensor, Tensor)            (aten_leaky_relu_default_1, [2, 2], [2, 2])                          {}\n",
      "call_function  getitem_1                               <built-in function getitem>                                                                                                                                                                                                                 (aten_max_pool2d_with_indices_default_1, 0)                          {}\n",
      "call_function  aten_view_copy_default                  <EdgeOpOverload: aten.view_copy.default>: schema = aten::view_copy(Tensor self, SymInt[] size) -> Tensor                                                                                                                                    (getitem_1, [1, 320])                                                {}\n",
      "call_function  aten_permute_copy_default               <EdgeOpOverload: aten.permute_copy.default>: schema = aten::permute_copy(Tensor self, int[] dims) -> Tensor                                                                                                                                 (arg4_1, [1, 0])                                                     {}\n",
      "call_function  aten_addmm_default                      <EdgeOpOverload: aten.addmm.default>: schema = aten::addmm(Tensor self, Tensor mat1, Tensor mat2, *, Scalar beta=1, Scalar alpha=1) -> Tensor                                                                                               (arg5_1, aten_view_copy_default, aten_permute_copy_default)          {}\n",
      "call_function  aten_leaky_relu_default_2               <EdgeOpOverload: aten.leaky_relu.default>: schema = aten::leaky_relu(Tensor self, Scalar negative_slope=0.01) -> Tensor                                                                                                                     (aten_addmm_default,)                                                {}\n",
      "call_function  aten_native_dropout_default             <EdgeOpOverload: aten.native_dropout.default>: schema = aten::native_dropout(Tensor input, float p, bool? train) -> (Tensor, Tensor)                                                                                                        (aten_leaky_relu_default_2, 0.1, True)                               {}\n",
      "call_function  getitem_2                               <built-in function getitem>                                                                                                                                                                                                                 (aten_native_dropout_default, 0)                                     {}\n",
      "output         output                                  output                                                                                                                                                                                                                                      ((getitem_2,),)                                                      {}\n"
     ]
    }
   ],
   "source": [
    "from executorch.exir import EdgeProgramManager, to_edge\n",
    "edge_program: EdgeProgramManager = to_edge(aten_dialect)\n",
    "print(\"Edge Dialect Graph\")\n",
    "to_be_lowered_module = edge_program.exported_program()\n",
    "to_be_lowered_module.graph.print_tabular()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Delegate to a Backend (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from executorch.exir.backend.backend_api import LoweredBackendModule, to_backend\n",
    "from executorch.exir.backend.test.backend_with_compiler_demo import (  # noqa\n",
    "    BackendWithCompilerDemo,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Executorch Programs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ExecuTorch Dialect\n",
      "opcode         name                                    target                              args                                                                 kwargs\n",
      "-------------  --------------------------------------  ----------------------------------  -------------------------------------------------------------------  ------------------------------------\n",
      "placeholder    arg0_1                                  arg0_1                              ()                                                                   {}\n",
      "placeholder    arg1_1                                  arg1_1                              ()                                                                   {}\n",
      "placeholder    arg2_1                                  arg2_1                              ()                                                                   {}\n",
      "placeholder    arg3_1                                  arg3_1                              ()                                                                   {}\n",
      "placeholder    arg4_1                                  arg4_1                              ()                                                                   {}\n",
      "placeholder    arg5_1                                  arg5_1                              ()                                                                   {}\n",
      "placeholder    arg6_1                                  arg6_1                              ()                                                                   {}\n",
      "call_function  alloc                                   <function alloc at 0x70ab6a27e560>  (((1, 10, 24, 24), torch.float32),)                                  {}\n",
      "call_function  aten_convolution_default                aten.convolution.out                (arg6_1, arg0_1, arg1_1, [1, 1], [0, 0], [1, 1], False, [0, 0], 1)   {'out': alloc}\n",
      "call_function  alloc_1                                 <function alloc at 0x70ab6a27e560>  (((1, 10, 24, 24), torch.float32),)                                  {}\n",
      "call_function  aten_leaky_relu_default                 aten.leaky_relu.out                 (aten_convolution_default,)                                          {'out': alloc_1}\n",
      "call_function  alloc_2                                 <function alloc at 0x70ab6a27e560>  (((1, 10, 12, 12), torch.float32),)                                  {}\n",
      "call_function  alloc_3                                 <function alloc at 0x70ab6a27e560>  (((1, 10, 12, 12), torch.int64),)                                    {}\n",
      "call_function  aten_max_pool2d_with_indices_default    aten.max_pool2d_with_indices.out    (aten_leaky_relu_default, [2, 2], [2, 2])                            {'out': alloc_2, 'indices': alloc_3}\n",
      "call_function  getitem                                 <built-in function getitem>         (aten_max_pool2d_with_indices_default, 0)                            {}\n",
      "call_function  alloc_4                                 <function alloc at 0x70ab6a27e560>  (((1, 20, 8, 8), torch.float32),)                                    {}\n",
      "call_function  aten_convolution_default_1              aten.convolution.out                (getitem, arg2_1, arg3_1, [1, 1], [0, 0], [1, 1], False, [0, 0], 1)  {'out': alloc_4}\n",
      "call_function  alloc_5                                 <function alloc at 0x70ab6a27e560>  (((1, 20, 8, 8), torch.float32),)                                    {}\n",
      "call_function  aten_leaky_relu_default_1               aten.leaky_relu.out                 (aten_convolution_default_1,)                                        {'out': alloc_5}\n",
      "call_function  alloc_6                                 <function alloc at 0x70ab6a27e560>  (((1, 20, 4, 4), torch.float32),)                                    {}\n",
      "call_function  alloc_7                                 <function alloc at 0x70ab6a27e560>  (((1, 20, 4, 4), torch.int64),)                                      {}\n",
      "call_function  aten_max_pool2d_with_indices_default_1  aten.max_pool2d_with_indices.out    (aten_leaky_relu_default_1, [2, 2], [2, 2])                          {'out': alloc_6, 'indices': alloc_7}\n",
      "call_function  getitem_1                               <built-in function getitem>         (aten_max_pool2d_with_indices_default_1, 0)                          {}\n",
      "call_function  alloc_8                                 <function alloc at 0x70ab6a27e560>  (((1, 320), torch.float32),)                                         {}\n",
      "call_function  aten_view_copy_default                  aten.view_copy.out                  (getitem_1, [1, 320])                                                {'out': alloc_8}\n",
      "call_function  alloc_9                                 <function alloc at 0x70ab6a27e560>  (((320, 10), torch.float32),)                                        {}\n",
      "call_function  aten_permute_copy_default               aten.permute_copy.out               (arg4_1, [1, 0])                                                     {'out': alloc_9}\n",
      "call_function  alloc_10                                <function alloc at 0x70ab6a27e560>  (((1, 10), torch.float32),)                                          {}\n",
      "call_function  aten_addmm_default                      aten.addmm.out                      (arg5_1, aten_view_copy_default, aten_permute_copy_default)          {'out': alloc_10}\n",
      "call_function  alloc_11                                <function alloc at 0x70ab6a27e560>  (((1, 10), torch.float32),)                                          {}\n",
      "call_function  aten_leaky_relu_default_2               aten.leaky_relu.out                 (aten_addmm_default,)                                                {'out': alloc_11}\n",
      "call_function  alloc_12                                <function alloc at 0x70ab6a27e560>  (((1, 10), torch.float32),)                                          {}\n",
      "call_function  alloc_13                                <function alloc at 0x70ab6a27e560>  (((1, 10), torch.bool),)                                             {}\n",
      "call_function  aten_native_dropout_default             aten.native_dropout.out             (aten_leaky_relu_default_2, 0.1, True)                               {'out0': alloc_12, 'out1': alloc_13}\n",
      "call_function  getitem_2                               <built-in function getitem>         (aten_native_dropout_default, 0)                                     {}\n",
      "output         output_1                                output                              ((getitem_2,),)                                                      {}\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from executorch.exir import ExecutorchBackendConfig, ExecutorchProgramManager\n",
    "from executorch.exir.passes import MemoryPlanningPass\n",
    "\n",
    "executorch_program: ExecutorchProgramManager = edge_program.to_executorch(\n",
    "    ExecutorchBackendConfig(\n",
    "        passes=[],  # User-defined passes\n",
    "        memory_planning_pass=MemoryPlanningPass(\n",
    "            \"greedy\"\n",
    "        ),  # Default memory planning pass\n",
    "    )\n",
    ")\n",
    "\n",
    "print(\"ExecuTorch Dialect\")\n",
    "print(executorch_program.exported_program().graph.print_tabular())\n",
    "\n",
    "\n",
    "with open(f\"{projroot}/model-weights/executorch/cnn/model.pte\", \"wb\") as file:\n",
    "    file.write(executorch_program.buffer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "machine-learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
