torch:
  device: cpu
  seed: 123

dataset:
  name: naodevils
  train_size: 0.7
  test_size: 0.3
  val_size: 0.1
  batch_size: 64
  load_data: True
  resample: True
  scale: False
  drive_url: https://drive.google.com/drive/folders/1VgtaMg66q9QxCf1VsVY1j75n5OXuWU2z?usp=sharing
  download_folder: data/whistle/saved

trainer:
  wandb_api_key: 41e4ba7425e35355cd4456863ed4cd9c73c084a3
  wandb_project: whistlenet_test
  experiment: ckconv
  epochs: 15
  patience: 5
  ckpt_path: "ckpt"
  resume_training: False
  min_delta: 1e-6

whistlenet:
  name: ckconv
  dropout: 0.2
  bias: True
  num_blocks: 4
  hidden_channels: 32
  optimizer:
    type: RAdam
    lr: 0.00001
    weight_decay: 0.00000001
  kernel:
    type: KernelNet
    size: 31
    no_layers: 3
    activation: Sine
    linear_type: Linear1d
    hidden_channels: 16
    dropout: 0.2
    omega_0: 750.0
    bias: True

baseline:
  name: naodevils
  dropout: 0.3
  hidden_dropout: 0.3
  bias: True
  optimizer:
    type: RAdam
    lr: 0.0001
    weight_decay: 0.000001