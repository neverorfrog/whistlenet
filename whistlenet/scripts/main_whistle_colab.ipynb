{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "boBFSANwGg0h"
      },
      "source": [
        "# Whistle Detection with Continuous Kernel Convolutional Networks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nlUJaWTYGg0i",
        "outputId": "77a7dab4-0b42-4d65-9b2d-c2a591586cf7"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "\n",
        "COLAB_RUNTIME = 'google.colab' in sys.modules\n",
        "if COLAB_RUNTIME:\n",
        "    !git init\n",
        "    !git remote add origin https://github.com/neverorfrog/whistlenet.git\n",
        "    !git pull origin main\n",
        "    !pip install -q -r requirements.txt\n",
        "else:\n",
        "    !pip install -q -r requirements.txt\n",
        "    !pre-commit install"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Config Loading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "329lZdVGGg0j"
      },
      "outputs": [],
      "source": [
        "from config import *\n",
        "import os\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "import torch\n",
        "import numpy as np\n",
        "from whistlenet.core.utils import project_root\n",
        "\n",
        "config_path = os.path.join(project_root(), \"config\",\"whistle_config.yaml\")\n",
        "config: Config = load_config(config_path)\n",
        "torch_config: TorchConfig = config.torch\n",
        "dataset_config: DatasetConfig = config.dataset\n",
        "trainer_config: TrainerConfig = config.trainer\n",
        "baseline_config: BaselineConfig = config.baseline\n",
        "whistlenet_config: WhistlenetConfig = config.whistlenet\n",
        "torch.manual_seed(torch_config.seed)\n",
        "np.random.seed(torch_config.seed)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Dataset Preparation\n",
        "\n",
        "The dataset has already been uploaded to google drive. The labelling was executed by hand by using Audacity. The processing was done as such:\n",
        "- Read every single .wav audio file with librosa\n",
        "- Do frequency analysis\n",
        "- Extract frequency associated amplitudes for every window\n",
        "\n",
        "This is an example of frequency plot. The highlited windows are whistle samples.\n",
        "\n",
        "<p align=\"left\">\n",
        "  <img src=\"../../docs/assets/image.png\" alt=\"Alt text\" width=\"300\"/>\n",
        "</p>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 968
        },
        "id": "TWNsPymWGg0j",
        "outputId": "6178213a-8d5f-48bf-f4a2-1c570dcdce30"
      },
      "outputs": [],
      "source": [
        "from whistlenet.data import WhistleDataset\n",
        "from whistlenet.core.utils import plot, NUM_FREQS\n",
        "from whistlenet.core.utils.audio import SampleType\n",
        "import gdown\n",
        "\n",
        "download_path = os.path.join(dataset_config.download_folder, dataset_config.name)\n",
        "gdown.download_folder(\n",
        "   dataset_config.drive_url, output=download_path\n",
        ")\n",
        "\n",
        "dataset = WhistleDataset(dataset_config)\n",
        "dataset.summarize()\n",
        "reshaped = dataset.train_data.reshape((dataset.train_data.data.shape[0], NUM_FREQS))\n",
        "plot(reshaped, dataset.train_data.labels, SampleType)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 366
        },
        "id": "RFf215BxGg0j",
        "outputId": "195e074f-db54-4adb-b163-30e76a18b984"
      },
      "outputs": [],
      "source": [
        "from whistlenet.models import WhistleNet, Baseline\n",
        "from whistlenet.core import LightningTrainer\n",
        "\n",
        "model = WhistleNet(in_channels=1, out_channels=1, config=whistlenet_config)\n",
        "trainer = LightningTrainer(trainer_config)\n",
        "trainer.fit(model,dataset)\n",
        "trainer.test(model, dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xLkFhlCmHQR0"
      },
      "outputs": [],
      "source": [
        "baseline = Baseline(config=baseline_config)\n",
        "trainer = LightningTrainer(trainer_config)\n",
        "trainer.fit(baseline,dataset)\n",
        "trainer.test(baseline, dataset)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "default",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
