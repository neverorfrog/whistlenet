{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../src')\n",
    "\n",
    "from utils import project_root\n",
    "projroot = project_root()\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL LOADED!\n",
      "tensor([[0.7794, 0.8375]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "from models import CCNN\n",
    "import yaml\n",
    "from omegaconf import OmegaConf\n",
    "from matplotlib import pyplot as plt\n",
    "from utils import num_params\n",
    "\n",
    "# Load the configuration\n",
    "file_path = \"config.yaml\"\n",
    "with open(file_path, 'r') as file:\n",
    "    config = OmegaConf.create(yaml.safe_load(file))\n",
    "\n",
    "name = \"test1_ccnn\"\n",
    "torch_model = CCNN(name, in_channels=1, out_channels=2, config=config)\n",
    "torch_model.load(name)\n",
    "torch_input = torch_model.example_input[0]\n",
    "torch_out = torch_model(torch_input)\n",
    "print(torch_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch IR graph at exception: graph(%input.1 : Float(1, 1, 513, strides=[513, 513, 1], requires_grad=0, device=cpu),\n",
      "      %backbone.0.conv1.bias : Float(2, strides=[1], requires_grad=1, device=cpu),\n",
      "      %backbone.0.conv1.Kernel.kernel_net.0.bias : Float(32, strides=[1], requires_grad=1, device=cpu),\n",
      "      %backbone.0.conv1.Kernel.kernel_net.0.parametrizations.weight.original0 : Float(32, 1, 1, strides=[1, 1, 1], requires_grad=1, device=cpu),\n",
      "      %backbone.0.conv1.Kernel.kernel_net.0.parametrizations.weight.original1 : Float(32, 1, 1, strides=[1, 1, 1], requires_grad=1, device=cpu),\n",
      "      %backbone.0.conv1.Kernel.kernel_net.3.bias : Float(32, strides=[1], requires_grad=1, device=cpu),\n",
      "      %backbone.0.conv1.Kernel.kernel_net.3.parametrizations.weight.original0 : Float(32, 1, 1, strides=[1, 1, 1], requires_grad=1, device=cpu),\n",
      "      %backbone.0.conv1.Kernel.kernel_net.3.parametrizations.weight.original1 : Float(32, 32, 1, strides=[32, 1, 1], requires_grad=1, device=cpu),\n",
      "      %backbone.0.conv1.Kernel.kernel_net.6.bias : Float(2, strides=[1], requires_grad=1, device=cpu),\n",
      "      %backbone.0.conv1.Kernel.kernel_net.6.parametrizations.weight.original0 : Float(2, 1, 1, strides=[1, 1, 1], requires_grad=1, device=cpu),\n",
      "      %backbone.0.conv1.Kernel.kernel_net.6.parametrizations.weight.original1 : Float(2, 32, 1, strides=[32, 1, 1], requires_grad=1, device=cpu),\n",
      "      %backbone.0.conv2.bias : Float(2, strides=[1], requires_grad=1, device=cpu),\n",
      "      %backbone.0.conv2.Kernel.kernel_net.0.bias : Float(32, strides=[1], requires_grad=1, device=cpu),\n",
      "      %backbone.0.conv2.Kernel.kernel_net.0.parametrizations.weight.original0 : Float(32, 1, 1, strides=[1, 1, 1], requires_grad=1, device=cpu),\n",
      "      %backbone.0.conv2.Kernel.kernel_net.0.parametrizations.weight.original1 : Float(32, 1, 1, strides=[1, 1, 1], requires_grad=1, device=cpu),\n",
      "      %backbone.0.conv2.Kernel.kernel_net.3.bias : Float(32, strides=[1], requires_grad=1, device=cpu),\n",
      "      %backbone.0.conv2.Kernel.kernel_net.3.parametrizations.weight.original0 : Float(32, 1, 1, strides=[1, 1, 1], requires_grad=1, device=cpu),\n",
      "      %backbone.0.conv2.Kernel.kernel_net.3.parametrizations.weight.original1 : Float(32, 32, 1, strides=[32, 1, 1], requires_grad=1, device=cpu),\n",
      "      %backbone.0.conv2.Kernel.kernel_net.6.bias : Float(4, strides=[1], requires_grad=1, device=cpu),\n",
      "      %backbone.0.conv2.Kernel.kernel_net.6.parametrizations.weight.original0 : Float(4, 1, 1, strides=[1, 1, 1], requires_grad=1, device=cpu),\n",
      "      %backbone.0.conv2.Kernel.kernel_net.6.parametrizations.weight.original1 : Float(4, 32, 1, strides=[32, 1, 1], requires_grad=1, device=cpu),\n",
      "      %backbone.0.norm1.layer_norm.weight : Float(2, strides=[1], requires_grad=1, device=cpu),\n",
      "      %backbone.0.norm1.layer_norm.bias : Float(2, strides=[1], requires_grad=1, device=cpu),\n",
      "      %backbone.0.norm2.layer_norm.weight : Float(2, strides=[1], requires_grad=1, device=cpu),\n",
      "      %backbone.0.norm2.layer_norm.bias : Float(2, strides=[1], requires_grad=1, device=cpu),\n",
      "      %backbone.0.shortcut.0.weight : Float(2, 1, 1, strides=[1, 1, 1], requires_grad=1, device=cpu),\n",
      "      %backbone.0.shortcut.0.bias : Float(2, strides=[1], requires_grad=1, device=cpu),\n",
      "      %linear.weight : Float(2, 2, strides=[2, 1], requires_grad=1, device=cpu),\n",
      "      %linear.bias : Float(2, strides=[1], requires_grad=1, device=cpu)):\n",
      "  %2113 : int[] = prim::Constant[value=[1]]()\n",
      "  %2114 : int[] = prim::Constant[value=[0]]()\n",
      "  %2157 : Bool(device=cpu) = prim::Constant[value={0}](), scope: torch.nn.modules.container.Sequential::backbone/ckconv.ckblock.CKBlock::backbone.0/torch.nn.modules.container.Sequential::shortcut/torch.nn.modules.conv.Conv1d::shortcut.0\n",
      "  %2158 : Long(device=cpu) = prim::Constant[value={1}](), scope: torch.nn.modules.container.Sequential::backbone/ckconv.ckblock.CKBlock::backbone.0/torch.nn.modules.container.Sequential::shortcut/torch.nn.modules.conv.Conv1d::shortcut.0\n",
      "  %2159 : Bool(device=cpu) = prim::Constant[value={1}](), scope: torch.nn.modules.container.Sequential::backbone/ckconv.ckblock.CKBlock::backbone.0/torch.nn.modules.container.Sequential::shortcut/torch.nn.modules.conv.Conv1d::shortcut.0\n",
      "  %1698 : Float(1, 2, 513, strides=[1026, 513, 1], requires_grad=0, device=cpu) = aten::_convolution(%input.1, %backbone.0.shortcut.0.weight, %backbone.0.shortcut.0.bias, %2113, %2114, %2113, %2157, %2114, %2158, %2157, %2157, %2159, %2159), scope: torch.nn.modules.container.Sequential::backbone/ckconv.ckblock.CKBlock::backbone.0/torch.nn.modules.container.Sequential::shortcut/torch.nn.modules.conv.Conv1d::shortcut.0 # /home/neverorfrog/.miniconda3/envs/ccnn/lib/python3.11/site-packages/torch/nn/modules/conv.py:306:0\n",
      "  %1703 : Long(device=cpu) = aten::size(%input.1, %2158), scope: torch.nn.modules.container.Sequential::backbone/ckconv.ckblock.CKBlock::backbone.0/ckconv.ckconv.CKConv::conv1 # /home/neverorfrog/code/whistle/whistlenet/tests/ccnn/../../src/ckconv/ckconv.py:49:0\n",
      "  %2160 : Long(device=cpu) = prim::Constant[value={2}](), scope: torch.nn.modules.container.Sequential::backbone/ckconv.ckblock.CKBlock::backbone.0/ckconv.ckconv.CKConv::conv1\n",
      "  %1707 : Long(device=cpu) = aten::size(%input.1, %2160), scope: torch.nn.modules.container.Sequential::backbone/ckconv.ckblock.CKBlock::backbone.0/ckconv.ckconv.CKConv::conv1 # /home/neverorfrog/code/whistle/whistlenet/tests/ccnn/../../src/ckconv/ckconv.py:49:0\n",
      "  %2161 : Long(device=cpu) = prim::Constant[value={0}](), scope: torch.nn.modules.container.Sequential::backbone/ckconv.ckblock.CKBlock::backbone.0/ckconv.ckconv.CKConv::conv1/torch.nn.modules.container.Sequential::kernel_net/torch.nn.utils.parametrize.ParametrizedConv1d::kernel_net.0/torch.nn.utils.parametrize.ParametrizationList::weight/torch.nn.utils.parametrizations._WeightNorm::weight.0\n",
      "  %1711 : Float(32, 1, 1, strides=[1, 1, 1], requires_grad=1, device=cpu) = aten::_weight_norm(%backbone.0.conv1.Kernel.kernel_net.0.parametrizations.weight.original1, %backbone.0.conv1.Kernel.kernel_net.0.parametrizations.weight.original0, %2161), scope: torch.nn.modules.container.Sequential::backbone/ckconv.ckblock.CKBlock::backbone.0/ckconv.ckconv.CKConv::conv1/torch.nn.modules.container.Sequential::kernel_net/torch.nn.utils.parametrize.ParametrizedConv1d::kernel_net.0/torch.nn.utils.parametrize.ParametrizationList::weight/torch.nn.utils.parametrizations._WeightNorm::weight.0 # /home/neverorfrog/.miniconda3/envs/ccnn/lib/python3.11/site-packages/torch/nn/utils/parametrizations.py:300:0\n",
      "  %1712 : Float(1, 1, 513, strides=[513, 513, 1], requires_grad=0, device=cpu) = prim::Constant[value=<Tensor>](), scope: torch.nn.modules.container.Sequential::backbone/ckconv.ckblock.CKBlock::backbone.0/ckconv.ckconv.CKConv::conv1/torch.nn.modules.container.Sequential::kernel_net/torch.nn.utils.parametrize.ParametrizedConv1d::kernel_net.0 # /home/neverorfrog/.miniconda3/envs/ccnn/lib/python3.11/site-packages/torch/nn/modules/conv.py:306:0\n",
      "  %x.1 : Float(1, 32, 513, strides=[16416, 513, 1], requires_grad=0, device=cpu) = aten::_convolution(%1712, %1711, %backbone.0.conv1.Kernel.kernel_net.0.bias, %2113, %2114, %2113, %2157, %2114, %2158, %2157, %2157, %2159, %2159), scope: torch.nn.modules.container.Sequential::backbone/ckconv.ckblock.CKBlock::backbone.0/ckconv.ckconv.CKConv::conv1/torch.nn.modules.container.Sequential::kernel_net/torch.nn.utils.parametrize.ParametrizedConv1d::kernel_net.0 # /home/neverorfrog/.miniconda3/envs/ccnn/lib/python3.11/site-packages/torch/nn/modules/conv.py:306:0\n",
      "  %2162 : Long(device=cpu) = prim::Constant[value={37}]()\n",
      "  %x.3 : Float(1, 32, 513, strides=[16416, 513, 1], requires_grad=1, device=cpu) = aten::mul(%x.1, %2162), scope: torch.nn.modules.container.Sequential::backbone/ckconv.ckblock.CKBlock::backbone.0/ckconv.ckconv.CKConv::conv1/torch.nn.modules.container.Sequential::kernel_net/ckconv.expression.Expression::kernel_net.1 # /home/neverorfrog/code/whistle/whistlenet/tests/ccnn/../../src/ckconv/expression.py:24:0\n",
      "  %input.3 : Float(1, 32, 513, strides=[16416, 513, 1], requires_grad=1, device=cpu) = aten::sin(%x.3), scope: torch.nn.modules.container.Sequential::backbone/ckconv.ckblock.CKBlock::backbone.0/ckconv.ckconv.CKConv::conv1/torch.nn.modules.container.Sequential::kernel_net/ckconv.expression.Expression::kernel_net.2 # /home/neverorfrog/code/whistle/whistlenet/tests/ccnn/../../src/ckconv/expression.py:31:0\n",
      "  %1732 : Float(32, 32, 1, strides=[32, 1, 1], requires_grad=1, device=cpu) = aten::_weight_norm(%backbone.0.conv1.Kernel.kernel_net.3.parametrizations.weight.original1, %backbone.0.conv1.Kernel.kernel_net.3.parametrizations.weight.original0, %2161), scope: torch.nn.modules.container.Sequential::backbone/ckconv.ckblock.CKBlock::backbone.0/ckconv.ckconv.CKConv::conv1/torch.nn.modules.container.Sequential::kernel_net/torch.nn.utils.parametrize.ParametrizedConv1d::kernel_net.3/torch.nn.utils.parametrize.ParametrizationList::weight/torch.nn.utils.parametrizations._WeightNorm::weight.0 # /home/neverorfrog/.miniconda3/envs/ccnn/lib/python3.11/site-packages/torch/nn/utils/parametrizations.py:300:0\n",
      "  %x.5 : Float(1, 32, 513, strides=[16416, 513, 1], requires_grad=0, device=cpu) = aten::_convolution(%input.3, %1732, %backbone.0.conv1.Kernel.kernel_net.3.bias, %2113, %2114, %2113, %2157, %2114, %2158, %2157, %2157, %2159, %2159), scope: torch.nn.modules.container.Sequential::backbone/ckconv.ckblock.CKBlock::backbone.0/ckconv.ckconv.CKConv::conv1/torch.nn.modules.container.Sequential::kernel_net/torch.nn.utils.parametrize.ParametrizedConv1d::kernel_net.3 # /home/neverorfrog/.miniconda3/envs/ccnn/lib/python3.11/site-packages/torch/nn/modules/conv.py:306:0\n",
      "  %2163 : Long(device=cpu) = prim::Constant[value={37}]()\n",
      "  %x.7 : Float(1, 32, 513, strides=[16416, 513, 1], requires_grad=1, device=cpu) = aten::mul(%x.5, %2163), scope: torch.nn.modules.container.Sequential::backbone/ckconv.ckblock.CKBlock::backbone.0/ckconv.ckconv.CKConv::conv1/torch.nn.modules.container.Sequential::kernel_net/ckconv.expression.Expression::kernel_net.4 # /home/neverorfrog/code/whistle/whistlenet/tests/ccnn/../../src/ckconv/expression.py:24:0\n",
      "  %input.5 : Float(1, 32, 513, strides=[16416, 513, 1], requires_grad=1, device=cpu) = aten::sin(%x.7), scope: torch.nn.modules.container.Sequential::backbone/ckconv.ckblock.CKBlock::backbone.0/ckconv.ckconv.CKConv::conv1/torch.nn.modules.container.Sequential::kernel_net/ckconv.expression.Expression::kernel_net.5 # /home/neverorfrog/code/whistle/whistlenet/tests/ccnn/../../src/ckconv/expression.py:31:0\n",
      "  %1752 : Float(2, 32, 1, strides=[32, 1, 1], requires_grad=1, device=cpu) = aten::_weight_norm(%backbone.0.conv1.Kernel.kernel_net.6.parametrizations.weight.original1, %backbone.0.conv1.Kernel.kernel_net.6.parametrizations.weight.original0, %2161), scope: torch.nn.modules.container.Sequential::backbone/ckconv.ckblock.CKBlock::backbone.0/ckconv.ckconv.CKConv::conv1/torch.nn.modules.container.Sequential::kernel_net/torch.nn.utils.parametrize.ParametrizedConv1d::kernel_net.6/torch.nn.utils.parametrize.ParametrizationList::weight/torch.nn.utils.parametrizations._WeightNorm::weight.0 # /home/neverorfrog/.miniconda3/envs/ccnn/lib/python3.11/site-packages/torch/nn/utils/parametrizations.py:300:0\n",
      "  %1767 : Float(1, 2, 513, strides=[1026, 513, 1], requires_grad=0, device=cpu) = aten::_convolution(%input.5, %1752, %backbone.0.conv1.Kernel.kernel_net.6.bias, %2113, %2114, %2113, %2157, %2114, %2158, %2157, %2157, %2159, %2159), scope: torch.nn.modules.container.Sequential::backbone/ckconv.ckblock.CKBlock::backbone.0/ckconv.ckconv.CKConv::conv1/torch.nn.modules.container.Sequential::kernel_net/torch.nn.utils.parametrize.ParametrizedConv1d::kernel_net.6 # /home/neverorfrog/.miniconda3/envs/ccnn/lib/python3.11/site-packages/torch/nn/modules/conv.py:306:0\n",
      "  %2164 : Long(device=cpu) = prim::Constant[value={-1}](), scope: torch.nn.modules.container.Sequential::backbone/ckconv.ckblock.CKBlock::backbone.0/ckconv.ckconv.CKConv::conv1\n",
      "  %1769 : int[] = prim::ListConstruct(%2164, %1703, %1707), scope: torch.nn.modules.container.Sequential::backbone/ckconv.ckblock.CKBlock::backbone.0/ckconv.ckconv.CKConv::conv1\n",
      "  %kernel.1 : Float(2, 1, 513, strides=[513, 513, 1], requires_grad=1, device=cpu) = aten::view(%1767, %1769), scope: torch.nn.modules.container.Sequential::backbone/ckconv.ckblock.CKBlock::backbone.0/ckconv.ckconv.CKConv::conv1 # /home/neverorfrog/code/whistle/whistlenet/tests/ccnn/../../src/ckconv/ckconv.py:53:0\n",
      "  %1801 : Long(device=cpu) = aten::size(%kernel.1, %2160), scope: torch.nn.modules.container.Sequential::backbone/ckconv.ckblock.CKBlock::backbone.0/ckconv.ckconv.CKConv::conv1 # /home/neverorfrog/code/whistle/whistlenet/tests/ccnn/../../src/ckconv/util.py:15:0\n",
      "  %2165 : Long(device=cpu) = prim::Constant[value={1}]()\n",
      "  %2150 : Long(requires_grad=0, device=cpu) = aten::sub(%1801, %2165, %2158), scope: torch.nn.modules.container.Sequential::backbone/ckconv.ckblock.CKBlock::backbone.0/ckconv.ckconv.CKConv::conv1 # /home/neverorfrog/code/whistle/whistlenet/tests/ccnn/../../src/ckconv/util.py:15:0\n",
      "  %1808 : int[] = prim::ListConstruct(%2150, %2161), scope: torch.nn.modules.container.Sequential::backbone/ckconv.ckblock.CKBlock::backbone.0/ckconv.ckconv.CKConv::conv1\n",
      "  %1809 : str = prim::Constant[value=\"constant\"](), scope: torch.nn.modules.container.Sequential::backbone/ckconv.ckblock.CKBlock::backbone.0/ckconv.ckconv.CKConv::conv1 # /home/neverorfrog/.miniconda3/envs/ccnn/lib/python3.11/site-packages/torch/nn/functional.py:4522:0\n",
      "  %2166 : Double(device=cpu) = prim::Constant[value={0}](), scope: torch.nn.modules.container.Sequential::backbone/ckconv.ckblock.CKBlock::backbone.0/ckconv.ckconv.CKConv::conv1\n",
      "  %1811 : Float(1, 1, 1025, strides=[1025, 1025, 1], requires_grad=0, device=cpu) = aten::pad(%input.1, %1808, %1809, %2166), scope: torch.nn.modules.container.Sequential::backbone/ckconv.ckblock.CKBlock::backbone.0/ckconv.ckconv.CKConv::conv1 # /home/neverorfrog/.miniconda3/envs/ccnn/lib/python3.11/site-packages/torch/nn/functional.py:4522:0\n",
      "  %1813 : Long(device=cpu) = aten::size(%1811, %2164), scope: torch.nn.modules.container.Sequential::backbone/ckconv.ckblock.CKBlock::backbone.0/ckconv.ckconv.CKConv::conv1 # /home/neverorfrog/code/whistle/whistlenet/tests/ccnn/../../src/ckconv/util.py:39:0\n",
      "  %1816 : Long(device=cpu) = aten::size(%kernel.1, %2164), scope: torch.nn.modules.container.Sequential::backbone/ckconv.ckblock.CKBlock::backbone.0/ckconv.ckconv.CKConv::conv1 # /home/neverorfrog/code/whistle/whistlenet/tests/ccnn/../../src/ckconv/util.py:39:0\n",
      "  %1819 : Long(requires_grad=0, device=cpu) = aten::sub(%1813, %1816, %2158), scope: torch.nn.modules.container.Sequential::backbone/ckconv.ckblock.CKBlock::backbone.0/ckconv.ckconv.CKConv::conv1 # /home/neverorfrog/code/whistle/whistlenet/tests/ccnn/../../src/ckconv/util.py:39:0\n",
      "  %1822 : int[] = prim::ListConstruct(%2161, %1819), scope: torch.nn.modules.container.Sequential::backbone/ckconv.ckblock.CKBlock::backbone.0/ckconv.ckconv.CKConv::conv1\n",
      "  %1824 : NoneType = prim::Constant(), scope: torch.nn.modules.container.Sequential::backbone/ckconv.ckblock.CKBlock::backbone.0/ckconv.ckconv.CKConv::conv1\n",
      "  %1825 : Float(2, 1, 1025, strides=[1025, 1025, 1], requires_grad=1, device=cpu) = aten::pad(%kernel.1, %1822, %1809, %1824), scope: torch.nn.modules.container.Sequential::backbone/ckconv.ckblock.CKBlock::backbone.0/ckconv.ckconv.CKConv::conv1 # /home/neverorfrog/.miniconda3/envs/ccnn/lib/python3.11/site-packages/torch/nn/functional.py:4522:0\n",
      "  %1829 : ComplexFloat(1, 1, 513, strides=[513, 513, 1], requires_grad=0, device=cpu) = aten::fft_rfft(%1811, %1824, %2164, %1824), scope: torch.nn.modules.container.Sequential::backbone/ckconv.ckblock.CKBlock::backbone.0/ckconv.ckconv.CKConv::conv1 # /home/neverorfrog/code/whistle/whistlenet/tests/ccnn/../../src/ckconv/util.py:47:0\n",
      "  %1833 : ComplexFloat(2, 1, 513, strides=[513, 513, 1], requires_grad=1, device=cpu) = aten::fft_rfft(%1825, %1824, %2164, %1824), scope: torch.nn.modules.container.Sequential::backbone/ckconv.ckblock.CKBlock::backbone.0/ckconv.ckconv.CKConv::conv1 # /home/neverorfrog/code/whistle/whistlenet/tests/ccnn/../../src/ckconv/util.py:48:0\n",
      "  %1834 : ComplexFloat(2, 1, 513, strides=[513, 513, 1], requires_grad=1, device=cpu) = aten::_conj(%1833), scope: torch.nn.modules.container.Sequential::backbone/ckconv.ckblock.CKBlock::backbone.0/ckconv.ckconv.CKConv::conv1 # /home/neverorfrog/code/whistle/whistlenet/tests/ccnn/../../src/ckconv/util.py:52:0\n",
      "  %1836 : ComplexFloat(1, 1, 1, 513, strides=[513, 513, 513, 1], requires_grad=0, device=cpu) = aten::unsqueeze(%1829, %2158), scope: torch.nn.modules.container.Sequential::backbone/ckconv.ckblock.CKBlock::backbone.0/ckconv.ckconv.CKConv::conv1 # /home/neverorfrog/code/whistle/whistlenet/tests/ccnn/../../src/ckconv/util.py:53:0\n",
      "  %1838 : ComplexFloat(1, 2, 1, 513, strides=[1026, 513, 513, 1], requires_grad=1, device=cpu) = aten::unsqueeze(%1834, %2161), scope: torch.nn.modules.container.Sequential::backbone/ckconv.ckblock.CKBlock::backbone.0/ckconv.ckconv.CKConv::conv1 # /home/neverorfrog/code/whistle/whistlenet/tests/ccnn/../../src/ckconv/util.py:53:0\n",
      "  %1839 : ComplexFloat(1, 2, 1, 513, strides=[1026, 513, 513, 1], requires_grad=1, device=cpu) = aten::mul(%1836, %1838), scope: torch.nn.modules.container.Sequential::backbone/ckconv.ckblock.CKBlock::backbone.0/ckconv.ckconv.CKConv::conv1 # /home/neverorfrog/code/whistle/whistlenet/tests/ccnn/../../src/ckconv/util.py:53:0\n",
      "  %2129 : int[] = prim::Constant[value=[2]]()\n",
      "  %1844 : ComplexFloat(1, 2, 513, strides=[1026, 513, 1], requires_grad=1, device=cpu) = aten::sum(%1839, %2129, %2157, %1824), scope: torch.nn.modules.container.Sequential::backbone/ckconv.ckblock.CKBlock::backbone.0/ckconv.ckconv.CKConv::conv1 # /home/neverorfrog/code/whistle/whistlenet/tests/ccnn/../../src/ckconv/util.py:53:0\n",
      "  %1848 : Float(1, 2, 1024, strides=[2048, 1024, 1], requires_grad=1, device=cpu) = aten::fft_irfft(%1844, %1824, %2164, %1824), scope: torch.nn.modules.container.Sequential::backbone/ckconv.ckblock.CKBlock::backbone.0/ckconv.ckconv.CKConv::conv1 # /home/neverorfrog/code/whistle/whistlenet/tests/ccnn/../../src/ckconv/util.py:59:0\n",
      "  %2167 : Long(device=cpu) = prim::Constant[value={6}](), scope: torch.nn.modules.container.Sequential::backbone/ckconv.ckblock.CKBlock::backbone.0/ckconv.ckconv.CKConv::conv1\n",
      "  %1853 : Float(1, 2, 1024, strides=[2048, 1024, 1], requires_grad=1, device=cpu) = aten::to(%1848, %2167, %2157, %2157, %1824), scope: torch.nn.modules.container.Sequential::backbone/ckconv.ckblock.CKBlock::backbone.0/ckconv.ckconv.CKConv::conv1 # /home/neverorfrog/code/whistle/whistlenet/tests/ccnn/../../src/ckconv/util.py:59:0\n",
      "  %2168 : Long(device=cpu) = prim::Constant[value={9223372036854775807}](), scope: torch.nn.modules.container.Sequential::backbone/ckconv.ckblock.CKBlock::backbone.0/ckconv.ckconv.CKConv::conv1\n",
      "  %1858 : Float(1, 2, 1024, strides=[2048, 1024, 1], requires_grad=1, device=cpu) = aten::slice(%1853, %2161, %2161, %2168, %2158), scope: torch.nn.modules.container.Sequential::backbone/ckconv.ckblock.CKBlock::backbone.0/ckconv.ckconv.CKConv::conv1 # /home/neverorfrog/code/whistle/whistlenet/tests/ccnn/../../src/ckconv/util.py:61:0\n",
      "  %1863 : Float(1, 2, 1024, strides=[2048, 1024, 1], requires_grad=1, device=cpu) = aten::slice(%1858, %2158, %2161, %2168, %2158), scope: torch.nn.modules.container.Sequential::backbone/ckconv.ckblock.CKBlock::backbone.0/ckconv.ckconv.CKConv::conv1 # /home/neverorfrog/code/whistle/whistlenet/tests/ccnn/../../src/ckconv/util.py:61:0\n",
      "  %1867 : Float(1, 2, 513, strides=[2048, 1024, 1], requires_grad=1, device=cpu) = aten::slice(%1863, %2160, %2161, %1707, %2158), scope: torch.nn.modules.container.Sequential::backbone/ckconv.ckblock.CKBlock::backbone.0/ckconv.ckconv.CKConv::conv1 # /home/neverorfrog/code/whistle/whistlenet/tests/ccnn/../../src/ckconv/util.py:61:0\n",
      "  %2130 : int[] = prim::Constant[value=[1, -1, 1]]()\n",
      "  %1872 : Float(1, 2, 1, strides=[2, 1, 1], requires_grad=1, device=cpu) = aten::view(%backbone.0.conv1.bias, %2130), scope: torch.nn.modules.container.Sequential::backbone/ckconv.ckblock.CKBlock::backbone.0/ckconv.ckconv.CKConv::conv1 # /home/neverorfrog/code/whistle/whistlenet/tests/ccnn/../../src/ckconv/util.py:65:0\n",
      "  %input.7 : Float(1, 2, 513, strides=[1026, 513, 1], requires_grad=1, device=cpu) = aten::add(%1867, %1872, %2158), scope: torch.nn.modules.container.Sequential::backbone/ckconv.ckblock.CKBlock::backbone.0/ckconv.ckconv.CKConv::conv1 # /home/neverorfrog/code/whistle/whistlenet/tests/ccnn/../../src/ckconv/util.py:65:0\n",
      "  %2169 : Double(device=cpu) = prim::Constant[value={1e-12}](), scope: torch.nn.modules.container.Sequential::backbone/ckconv.ckblock.CKBlock::backbone.0/ckconv.customlayers.LayerNorm::norm1/torch.nn.modules.normalization.GroupNorm::layer_norm\n",
      "  %1899 : Float(1, 2, 513, strides=[1026, 513, 1], requires_grad=1, device=cpu) = aten::group_norm(%input.7, %2158, %backbone.0.norm1.layer_norm.weight, %backbone.0.norm1.layer_norm.bias, %2169, %2159), scope: torch.nn.modules.container.Sequential::backbone/ckconv.ckblock.CKBlock::backbone.0/ckconv.customlayers.LayerNorm::norm1/torch.nn.modules.normalization.GroupNorm::layer_norm # /home/neverorfrog/.miniconda3/envs/ccnn/lib/python3.11/site-packages/torch/nn/functional.py:2588:0\n",
      "  %input.9 : Float(1, 2, 513, strides=[1026, 513, 1], requires_grad=1, device=cpu) = aten::relu(%1899), scope: torch.nn.modules.container.Sequential::backbone/ckconv.ckblock.CKBlock::backbone.0 # /home/neverorfrog/code/whistle/whistlenet/tests/ccnn/../../src/ckconv/ckblock.py:63:0\n",
      "  %2170 : Double(device=cpu) = prim::Constant[value={0.5}](), scope: torch.nn.modules.container.Sequential::backbone/ckconv.ckblock.CKBlock::backbone.0/torch.nn.modules.dropout.Dropout::dropout\n",
      "  %x : Float(1, 2, 513, strides=[1026, 513, 1], requires_grad=1, device=cpu) = aten::dropout(%input.9, %2170, %2157), scope: torch.nn.modules.container.Sequential::backbone/ckconv.ckblock.CKBlock::backbone.0/torch.nn.modules.dropout.Dropout::dropout # /home/neverorfrog/.miniconda3/envs/ccnn/lib/python3.11/site-packages/torch/nn/functional.py:1295:0\n",
      "  %1908 : Long(device=cpu) = aten::size(%x, %2158), scope: torch.nn.modules.container.Sequential::backbone/ckconv.ckblock.CKBlock::backbone.0/ckconv.ckconv.CKConv::conv2 # /home/neverorfrog/code/whistle/whistlenet/tests/ccnn/../../src/ckconv/ckconv.py:49:0\n",
      "  %1912 : Long(device=cpu) = aten::size(%x, %2160), scope: torch.nn.modules.container.Sequential::backbone/ckconv.ckblock.CKBlock::backbone.0/ckconv.ckconv.CKConv::conv2 # /home/neverorfrog/code/whistle/whistlenet/tests/ccnn/../../src/ckconv/ckconv.py:49:0\n",
      "  %1916 : Float(32, 1, 1, strides=[1, 1, 1], requires_grad=1, device=cpu) = aten::_weight_norm(%backbone.0.conv2.Kernel.kernel_net.0.parametrizations.weight.original1, %backbone.0.conv2.Kernel.kernel_net.0.parametrizations.weight.original0, %2161), scope: torch.nn.modules.container.Sequential::backbone/ckconv.ckblock.CKBlock::backbone.0/ckconv.ckconv.CKConv::conv2/torch.nn.modules.container.Sequential::kernel_net/torch.nn.utils.parametrize.ParametrizedConv1d::kernel_net.0/torch.nn.utils.parametrize.ParametrizationList::weight/torch.nn.utils.parametrizations._WeightNorm::weight.0 # /home/neverorfrog/.miniconda3/envs/ccnn/lib/python3.11/site-packages/torch/nn/utils/parametrizations.py:300:0\n",
      "  %x.9 : Float(1, 32, 513, strides=[16416, 513, 1], requires_grad=0, device=cpu) = aten::_convolution(%1712, %1916, %backbone.0.conv2.Kernel.kernel_net.0.bias, %2113, %2114, %2113, %2157, %2114, %2158, %2157, %2157, %2159, %2159), scope: torch.nn.modules.container.Sequential::backbone/ckconv.ckblock.CKBlock::backbone.0/ckconv.ckconv.CKConv::conv2/torch.nn.modules.container.Sequential::kernel_net/torch.nn.utils.parametrize.ParametrizedConv1d::kernel_net.0 # /home/neverorfrog/.miniconda3/envs/ccnn/lib/python3.11/site-packages/torch/nn/modules/conv.py:306:0\n",
      "  %2171 : Long(device=cpu) = prim::Constant[value={37}]()\n",
      "  %x.11 : Float(1, 32, 513, strides=[16416, 513, 1], requires_grad=1, device=cpu) = aten::mul(%x.9, %2171), scope: torch.nn.modules.container.Sequential::backbone/ckconv.ckblock.CKBlock::backbone.0/ckconv.ckconv.CKConv::conv2/torch.nn.modules.container.Sequential::kernel_net/ckconv.expression.Expression::kernel_net.1 # /home/neverorfrog/code/whistle/whistlenet/tests/ccnn/../../src/ckconv/expression.py:24:0\n",
      "  %input.11 : Float(1, 32, 513, strides=[16416, 513, 1], requires_grad=1, device=cpu) = aten::sin(%x.11), scope: torch.nn.modules.container.Sequential::backbone/ckconv.ckblock.CKBlock::backbone.0/ckconv.ckconv.CKConv::conv2/torch.nn.modules.container.Sequential::kernel_net/ckconv.expression.Expression::kernel_net.2 # /home/neverorfrog/code/whistle/whistlenet/tests/ccnn/../../src/ckconv/expression.py:31:0\n",
      "  %1937 : Float(32, 32, 1, strides=[32, 1, 1], requires_grad=1, device=cpu) = aten::_weight_norm(%backbone.0.conv2.Kernel.kernel_net.3.parametrizations.weight.original1, %backbone.0.conv2.Kernel.kernel_net.3.parametrizations.weight.original0, %2161), scope: torch.nn.modules.container.Sequential::backbone/ckconv.ckblock.CKBlock::backbone.0/ckconv.ckconv.CKConv::conv2/torch.nn.modules.container.Sequential::kernel_net/torch.nn.utils.parametrize.ParametrizedConv1d::kernel_net.3/torch.nn.utils.parametrize.ParametrizationList::weight/torch.nn.utils.parametrizations._WeightNorm::weight.0 # /home/neverorfrog/.miniconda3/envs/ccnn/lib/python3.11/site-packages/torch/nn/utils/parametrizations.py:300:0\n",
      "  %x.13 : Float(1, 32, 513, strides=[16416, 513, 1], requires_grad=0, device=cpu) = aten::_convolution(%input.11, %1937, %backbone.0.conv2.Kernel.kernel_net.3.bias, %2113, %2114, %2113, %2157, %2114, %2158, %2157, %2157, %2159, %2159), scope: torch.nn.modules.container.Sequential::backbone/ckconv.ckblock.CKBlock::backbone.0/ckconv.ckconv.CKConv::conv2/torch.nn.modules.container.Sequential::kernel_net/torch.nn.utils.parametrize.ParametrizedConv1d::kernel_net.3 # /home/neverorfrog/.miniconda3/envs/ccnn/lib/python3.11/site-packages/torch/nn/modules/conv.py:306:0\n",
      "  %2172 : Long(device=cpu) = prim::Constant[value={37}]()\n",
      "  %x.15 : Float(1, 32, 513, strides=[16416, 513, 1], requires_grad=1, device=cpu) = aten::mul(%x.13, %2172), scope: torch.nn.modules.container.Sequential::backbone/ckconv.ckblock.CKBlock::backbone.0/ckconv.ckconv.CKConv::conv2/torch.nn.modules.container.Sequential::kernel_net/ckconv.expression.Expression::kernel_net.4 # /home/neverorfrog/code/whistle/whistlenet/tests/ccnn/../../src/ckconv/expression.py:24:0\n",
      "  %input.13 : Float(1, 32, 513, strides=[16416, 513, 1], requires_grad=1, device=cpu) = aten::sin(%x.15), scope: torch.nn.modules.container.Sequential::backbone/ckconv.ckblock.CKBlock::backbone.0/ckconv.ckconv.CKConv::conv2/torch.nn.modules.container.Sequential::kernel_net/ckconv.expression.Expression::kernel_net.5 # /home/neverorfrog/code/whistle/whistlenet/tests/ccnn/../../src/ckconv/expression.py:31:0\n",
      "  %1957 : Float(4, 32, 1, strides=[32, 1, 1], requires_grad=1, device=cpu) = aten::_weight_norm(%backbone.0.conv2.Kernel.kernel_net.6.parametrizations.weight.original1, %backbone.0.conv2.Kernel.kernel_net.6.parametrizations.weight.original0, %2161), scope: torch.nn.modules.container.Sequential::backbone/ckconv.ckblock.CKBlock::backbone.0/ckconv.ckconv.CKConv::conv2/torch.nn.modules.container.Sequential::kernel_net/torch.nn.utils.parametrize.ParametrizedConv1d::kernel_net.6/torch.nn.utils.parametrize.ParametrizationList::weight/torch.nn.utils.parametrizations._WeightNorm::weight.0 # /home/neverorfrog/.miniconda3/envs/ccnn/lib/python3.11/site-packages/torch/nn/utils/parametrizations.py:300:0\n",
      "  %1972 : Float(1, 4, 513, strides=[2052, 513, 1], requires_grad=0, device=cpu) = aten::_convolution(%input.13, %1957, %backbone.0.conv2.Kernel.kernel_net.6.bias, %2113, %2114, %2113, %2157, %2114, %2158, %2157, %2157, %2159, %2159), scope: torch.nn.modules.container.Sequential::backbone/ckconv.ckblock.CKBlock::backbone.0/ckconv.ckconv.CKConv::conv2/torch.nn.modules.container.Sequential::kernel_net/torch.nn.utils.parametrize.ParametrizedConv1d::kernel_net.6 # /home/neverorfrog/.miniconda3/envs/ccnn/lib/python3.11/site-packages/torch/nn/modules/conv.py:306:0\n",
      "  %1974 : int[] = prim::ListConstruct(%2164, %1908, %1912), scope: torch.nn.modules.container.Sequential::backbone/ckconv.ckblock.CKBlock::backbone.0/ckconv.ckconv.CKConv::conv2\n",
      "  %kernel : Float(2, 2, 513, strides=[1026, 513, 1], requires_grad=1, device=cpu) = aten::view(%1972, %1974), scope: torch.nn.modules.container.Sequential::backbone/ckconv.ckblock.CKBlock::backbone.0/ckconv.ckconv.CKConv::conv2 # /home/neverorfrog/code/whistle/whistlenet/tests/ccnn/../../src/ckconv/ckconv.py:53:0\n",
      "  %2006 : Long(device=cpu) = aten::size(%kernel, %2160), scope: torch.nn.modules.container.Sequential::backbone/ckconv.ckblock.CKBlock::backbone.0/ckconv.ckconv.CKConv::conv2 # /home/neverorfrog/code/whistle/whistlenet/tests/ccnn/../../src/ckconv/util.py:15:0\n",
      "  %2173 : Long(device=cpu) = prim::Constant[value={1}]()\n",
      "  %2156 : Long(requires_grad=0, device=cpu) = aten::sub(%2006, %2173, %2158), scope: torch.nn.modules.container.Sequential::backbone/ckconv.ckblock.CKBlock::backbone.0/ckconv.ckconv.CKConv::conv2 # /home/neverorfrog/code/whistle/whistlenet/tests/ccnn/../../src/ckconv/util.py:15:0\n",
      "  %2013 : int[] = prim::ListConstruct(%2156, %2161), scope: torch.nn.modules.container.Sequential::backbone/ckconv.ckblock.CKBlock::backbone.0/ckconv.ckconv.CKConv::conv2\n",
      "  %2016 : Float(1, 2, 1025, strides=[2050, 1025, 1], requires_grad=1, device=cpu) = aten::pad(%x, %2013, %1809, %2166), scope: torch.nn.modules.container.Sequential::backbone/ckconv.ckblock.CKBlock::backbone.0/ckconv.ckconv.CKConv::conv2 # /home/neverorfrog/.miniconda3/envs/ccnn/lib/python3.11/site-packages/torch/nn/functional.py:4522:0\n",
      "  %2018 : Long(device=cpu) = aten::size(%2016, %2164), scope: torch.nn.modules.container.Sequential::backbone/ckconv.ckblock.CKBlock::backbone.0/ckconv.ckconv.CKConv::conv2 # /home/neverorfrog/code/whistle/whistlenet/tests/ccnn/../../src/ckconv/util.py:39:0\n",
      "  %2021 : Long(device=cpu) = aten::size(%kernel, %2164), scope: torch.nn.modules.container.Sequential::backbone/ckconv.ckblock.CKBlock::backbone.0/ckconv.ckconv.CKConv::conv2 # /home/neverorfrog/code/whistle/whistlenet/tests/ccnn/../../src/ckconv/util.py:39:0\n",
      "  %2024 : Long(requires_grad=0, device=cpu) = aten::sub(%2018, %2021, %2158), scope: torch.nn.modules.container.Sequential::backbone/ckconv.ckblock.CKBlock::backbone.0/ckconv.ckconv.CKConv::conv2 # /home/neverorfrog/code/whistle/whistlenet/tests/ccnn/../../src/ckconv/util.py:39:0\n",
      "  %2027 : int[] = prim::ListConstruct(%2161, %2024), scope: torch.nn.modules.container.Sequential::backbone/ckconv.ckblock.CKBlock::backbone.0/ckconv.ckconv.CKConv::conv2\n",
      "  %2030 : Float(2, 2, 1025, strides=[2050, 1025, 1], requires_grad=1, device=cpu) = aten::pad(%kernel, %2027, %1809, %1824), scope: torch.nn.modules.container.Sequential::backbone/ckconv.ckblock.CKBlock::backbone.0/ckconv.ckconv.CKConv::conv2 # /home/neverorfrog/.miniconda3/envs/ccnn/lib/python3.11/site-packages/torch/nn/functional.py:4522:0\n",
      "  %2034 : ComplexFloat(1, 2, 513, strides=[1026, 513, 1], requires_grad=1, device=cpu) = aten::fft_rfft(%2016, %1824, %2164, %1824), scope: torch.nn.modules.container.Sequential::backbone/ckconv.ckblock.CKBlock::backbone.0/ckconv.ckconv.CKConv::conv2 # /home/neverorfrog/code/whistle/whistlenet/tests/ccnn/../../src/ckconv/util.py:47:0\n",
      "  %2038 : ComplexFloat(2, 2, 513, strides=[1026, 513, 1], requires_grad=1, device=cpu) = aten::fft_rfft(%2030, %1824, %2164, %1824), scope: torch.nn.modules.container.Sequential::backbone/ckconv.ckblock.CKBlock::backbone.0/ckconv.ckconv.CKConv::conv2 # /home/neverorfrog/code/whistle/whistlenet/tests/ccnn/../../src/ckconv/util.py:48:0\n",
      "  %2039 : ComplexFloat(2, 2, 513, strides=[1026, 513, 1], requires_grad=1, device=cpu) = aten::_conj(%2038), scope: torch.nn.modules.container.Sequential::backbone/ckconv.ckblock.CKBlock::backbone.0/ckconv.ckconv.CKConv::conv2 # /home/neverorfrog/code/whistle/whistlenet/tests/ccnn/../../src/ckconv/util.py:52:0\n",
      "  %2041 : ComplexFloat(1, 1, 2, 513, strides=[1026, 1026, 513, 1], requires_grad=1, device=cpu) = aten::unsqueeze(%2034, %2158), scope: torch.nn.modules.container.Sequential::backbone/ckconv.ckblock.CKBlock::backbone.0/ckconv.ckconv.CKConv::conv2 # /home/neverorfrog/code/whistle/whistlenet/tests/ccnn/../../src/ckconv/util.py:53:0\n",
      "  %2043 : ComplexFloat(1, 2, 2, 513, strides=[2052, 1026, 513, 1], requires_grad=1, device=cpu) = aten::unsqueeze(%2039, %2161), scope: torch.nn.modules.container.Sequential::backbone/ckconv.ckblock.CKBlock::backbone.0/ckconv.ckconv.CKConv::conv2 # /home/neverorfrog/code/whistle/whistlenet/tests/ccnn/../../src/ckconv/util.py:53:0\n",
      "  %2044 : ComplexFloat(1, 2, 2, 513, strides=[2052, 1026, 513, 1], requires_grad=1, device=cpu) = aten::mul(%2041, %2043), scope: torch.nn.modules.container.Sequential::backbone/ckconv.ckblock.CKBlock::backbone.0/ckconv.ckconv.CKConv::conv2 # /home/neverorfrog/code/whistle/whistlenet/tests/ccnn/../../src/ckconv/util.py:53:0\n",
      "  %2049 : ComplexFloat(1, 2, 513, strides=[1026, 513, 1], requires_grad=1, device=cpu) = aten::sum(%2044, %2129, %2157, %1824), scope: torch.nn.modules.container.Sequential::backbone/ckconv.ckblock.CKBlock::backbone.0/ckconv.ckconv.CKConv::conv2 # /home/neverorfrog/code/whistle/whistlenet/tests/ccnn/../../src/ckconv/util.py:53:0\n",
      "  %2053 : Float(1, 2, 1024, strides=[2048, 1024, 1], requires_grad=1, device=cpu) = aten::fft_irfft(%2049, %1824, %2164, %1824), scope: torch.nn.modules.container.Sequential::backbone/ckconv.ckblock.CKBlock::backbone.0/ckconv.ckconv.CKConv::conv2 # /home/neverorfrog/code/whistle/whistlenet/tests/ccnn/../../src/ckconv/util.py:59:0\n",
      "  %2058 : Float(1, 2, 1024, strides=[2048, 1024, 1], requires_grad=1, device=cpu) = aten::to(%2053, %2167, %2157, %2157, %1824), scope: torch.nn.modules.container.Sequential::backbone/ckconv.ckblock.CKBlock::backbone.0/ckconv.ckconv.CKConv::conv2 # /home/neverorfrog/code/whistle/whistlenet/tests/ccnn/../../src/ckconv/util.py:59:0\n",
      "  %2063 : Float(1, 2, 1024, strides=[2048, 1024, 1], requires_grad=1, device=cpu) = aten::slice(%2058, %2161, %2161, %2168, %2158), scope: torch.nn.modules.container.Sequential::backbone/ckconv.ckblock.CKBlock::backbone.0/ckconv.ckconv.CKConv::conv2 # /home/neverorfrog/code/whistle/whistlenet/tests/ccnn/../../src/ckconv/util.py:61:0\n",
      "  %2068 : Float(1, 2, 1024, strides=[2048, 1024, 1], requires_grad=1, device=cpu) = aten::slice(%2063, %2158, %2161, %2168, %2158), scope: torch.nn.modules.container.Sequential::backbone/ckconv.ckblock.CKBlock::backbone.0/ckconv.ckconv.CKConv::conv2 # /home/neverorfrog/code/whistle/whistlenet/tests/ccnn/../../src/ckconv/util.py:61:0\n",
      "  %2072 : Float(1, 2, 513, strides=[2048, 1024, 1], requires_grad=1, device=cpu) = aten::slice(%2068, %2160, %2161, %1912, %2158), scope: torch.nn.modules.container.Sequential::backbone/ckconv.ckblock.CKBlock::backbone.0/ckconv.ckconv.CKConv::conv2 # /home/neverorfrog/code/whistle/whistlenet/tests/ccnn/../../src/ckconv/util.py:61:0\n",
      "  %2077 : Float(1, 2, 1, strides=[2, 1, 1], requires_grad=1, device=cpu) = aten::view(%backbone.0.conv2.bias, %2130), scope: torch.nn.modules.container.Sequential::backbone/ckconv.ckblock.CKBlock::backbone.0/ckconv.ckconv.CKConv::conv2 # /home/neverorfrog/code/whistle/whistlenet/tests/ccnn/../../src/ckconv/util.py:65:0\n",
      "  %input.15 : Float(1, 2, 513, strides=[1026, 513, 1], requires_grad=1, device=cpu) = aten::add(%2072, %2077, %2158), scope: torch.nn.modules.container.Sequential::backbone/ckconv.ckblock.CKBlock::backbone.0/ckconv.ckconv.CKConv::conv2 # /home/neverorfrog/code/whistle/whistlenet/tests/ccnn/../../src/ckconv/util.py:65:0\n",
      "  %2104 : Float(1, 2, 513, strides=[1026, 513, 1], requires_grad=1, device=cpu) = aten::group_norm(%input.15, %2158, %backbone.0.norm2.layer_norm.weight, %backbone.0.norm2.layer_norm.bias, %2169, %2159), scope: torch.nn.modules.container.Sequential::backbone/ckconv.ckblock.CKBlock::backbone.0/ckconv.customlayers.LayerNorm::norm2/torch.nn.modules.normalization.GroupNorm::layer_norm # /home/neverorfrog/.miniconda3/envs/ccnn/lib/python3.11/site-packages/torch/nn/functional.py:2588:0\n",
      "  %input : Float(1, 2, 513, strides=[1026, 513, 1], requires_grad=1, device=cpu) = aten::relu(%2104), scope: torch.nn.modules.container.Sequential::backbone/ckconv.ckblock.CKBlock::backbone.0 # /home/neverorfrog/code/whistle/whistlenet/tests/ccnn/../../src/ckconv/ckblock.py:65:0\n",
      "  %2108 : Float(1, 2, 513, strides=[1026, 513, 1], requires_grad=1, device=cpu) = aten::dropout(%input, %2170, %2157), scope: torch.nn.modules.container.Sequential::backbone/ckconv.ckblock.CKBlock::backbone.0/torch.nn.modules.dropout.Dropout::dropout # /home/neverorfrog/.miniconda3/envs/ccnn/lib/python3.11/site-packages/torch/nn/functional.py:1295:0\n",
      "  %2110 : Float(1, 2, 513, strides=[1026, 513, 1], requires_grad=1, device=cpu) = aten::add(%2108, %1698, %2158), scope: torch.nn.modules.container.Sequential::backbone/ckconv.ckblock.CKBlock::backbone.0 # /home/neverorfrog/code/whistle/whistlenet/tests/ccnn/../../src/ckconv/ckblock.py:65:0\n",
      "  %2111 : Float(1, 2, 513, strides=[1026, 513, 1], requires_grad=1, device=cpu) = aten::relu(%2110), scope: torch.nn.modules.container.Sequential::backbone/ckconv.ckblock.CKBlock::backbone.0 # /home/neverorfrog/code/whistle/whistlenet/tests/ccnn/../../src/ckconv/ckblock.py:64:0\n",
      "  %461 : Float(1, 2, 513, strides=[1026, 513, 1], requires_grad=1, device=cpu) = aten::slice(%2111, %2161, %2161, %2168, %2158) # /home/neverorfrog/code/whistle/whistlenet/tests/ccnn/../../src/models/ccnn.py:31:0\n",
      "  %466 : Float(1, 2, 513, strides=[1026, 513, 1], requires_grad=1, device=cpu) = aten::slice(%461, %2158, %2161, %2168, %2158) # /home/neverorfrog/code/whistle/whistlenet/tests/ccnn/../../src/models/ccnn.py:31:0\n",
      "  %469 : Float(1, 2, strides=[1026, 513], requires_grad=1, device=cpu) = aten::select(%466, %2160, %2164) # /home/neverorfrog/code/whistle/whistlenet/tests/ccnn/../../src/models/ccnn.py:31:0\n",
      "  %2112 : Float(1, 2, strides=[2, 1], requires_grad=1, device=cpu) = aten::linear(%469, %linear.weight, %linear.bias), scope: torch.nn.modules.linear.Linear::linear # /home/neverorfrog/.miniconda3/envs/ccnn/lib/python3.11/site-packages/torch/nn/modules/linear.py:116:0\n",
      "  return (%2112)\n",
      "\n"
     ]
    },
    {
     "ename": "UnsupportedOperatorError",
     "evalue": "Exporting the operator 'aten::fft_rfft' to ONNX opset version 17 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub: https://github.com/pytorch/pytorch/issues.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnsupportedOperatorError\u001b[0m                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 8\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m      6\u001b[0m torch_model\u001b[38;5;241m.\u001b[39meval()\n\u001b[0;32m----> 8\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43monnx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexport\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtorch_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtorch_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mname\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m.onnx\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minput\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43moutput\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m onnx_model \u001b[38;5;241m=\u001b[39m onnx\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.onnx\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     18\u001b[0m onnx\u001b[38;5;241m.\u001b[39mchecker\u001b[38;5;241m.\u001b[39mcheck_model(onnx_model)\n",
      "File \u001b[0;32m~/.miniconda3/envs/ccnn/lib/python3.11/site-packages/torch/onnx/utils.py:516\u001b[0m, in \u001b[0;36mexport\u001b[0;34m(model, args, f, export_params, verbose, training, input_names, output_names, operator_export_type, opset_version, do_constant_folding, dynamic_axes, keep_initializers_as_inputs, custom_opsets, export_modules_as_functions, autograd_inlining)\u001b[0m\n\u001b[1;32m    189\u001b[0m \u001b[38;5;129m@_beartype\u001b[39m\u001b[38;5;241m.\u001b[39mbeartype\n\u001b[1;32m    190\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mexport\u001b[39m(\n\u001b[1;32m    191\u001b[0m     model: Union[torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mModule, torch\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39mScriptModule, torch\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39mScriptFunction],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    208\u001b[0m     autograd_inlining: Optional[\u001b[38;5;28mbool\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    209\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    210\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Exports a model into ONNX format.\u001b[39;00m\n\u001b[1;32m    211\u001b[0m \n\u001b[1;32m    212\u001b[0m \u001b[38;5;124;03m    If ``model`` is not a :class:`torch.jit.ScriptModule` nor a\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    513\u001b[0m \u001b[38;5;124;03m            All errors are subclasses of :class:`errors.OnnxExporterError`.\u001b[39;00m\n\u001b[1;32m    514\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 516\u001b[0m     \u001b[43m_export\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    517\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    518\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    519\u001b[0m \u001b[43m        \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    520\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexport_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    521\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    522\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    524\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    525\u001b[0m \u001b[43m        \u001b[49m\u001b[43moperator_export_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moperator_export_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    526\u001b[0m \u001b[43m        \u001b[49m\u001b[43mopset_version\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mopset_version\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    527\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdo_constant_folding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdo_constant_folding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    528\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdynamic_axes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdynamic_axes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    529\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkeep_initializers_as_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_initializers_as_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    530\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcustom_opsets\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcustom_opsets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    531\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexport_modules_as_functions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexport_modules_as_functions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    532\u001b[0m \u001b[43m        \u001b[49m\u001b[43mautograd_inlining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mautograd_inlining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    533\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.miniconda3/envs/ccnn/lib/python3.11/site-packages/torch/onnx/utils.py:1612\u001b[0m, in \u001b[0;36m_export\u001b[0;34m(model, args, f, export_params, verbose, training, input_names, output_names, operator_export_type, export_type, opset_version, do_constant_folding, dynamic_axes, keep_initializers_as_inputs, fixed_batch_size, custom_opsets, add_node_names, onnx_shape_inference, export_modules_as_functions, autograd_inlining)\u001b[0m\n\u001b[1;32m   1609\u001b[0m     dynamic_axes \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m   1610\u001b[0m _validate_dynamic_axes(dynamic_axes, model, input_names, output_names)\n\u001b[0;32m-> 1612\u001b[0m graph, params_dict, torch_out \u001b[38;5;241m=\u001b[39m \u001b[43m_model_to_graph\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1613\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1614\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1615\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1616\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1617\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1618\u001b[0m \u001b[43m    \u001b[49m\u001b[43moperator_export_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1619\u001b[0m \u001b[43m    \u001b[49m\u001b[43mval_do_constant_folding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1620\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfixed_batch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfixed_batch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1621\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtraining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1622\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdynamic_axes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdynamic_axes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1623\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1625\u001b[0m \u001b[38;5;66;03m# TODO: Don't allocate a in-memory string for the protobuf\u001b[39;00m\n\u001b[1;32m   1626\u001b[0m defer_weight_export \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   1627\u001b[0m     export_type \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _exporter_states\u001b[38;5;241m.\u001b[39mExportTypes\u001b[38;5;241m.\u001b[39mPROTOBUF_FILE\n\u001b[1;32m   1628\u001b[0m )\n",
      "File \u001b[0;32m~/.miniconda3/envs/ccnn/lib/python3.11/site-packages/torch/onnx/utils.py:1138\u001b[0m, in \u001b[0;36m_model_to_graph\u001b[0;34m(model, args, verbose, input_names, output_names, operator_export_type, do_constant_folding, _disable_torch_constant_prop, fixed_batch_size, training, dynamic_axes)\u001b[0m\n\u001b[1;32m   1135\u001b[0m params_dict \u001b[38;5;241m=\u001b[39m _get_named_param_dict(graph, params)\n\u001b[1;32m   1137\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1138\u001b[0m     graph \u001b[38;5;241m=\u001b[39m \u001b[43m_optimize_graph\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1139\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgraph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1140\u001b[0m \u001b[43m        \u001b[49m\u001b[43moperator_export_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1141\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_disable_torch_constant_prop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_disable_torch_constant_prop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1142\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfixed_batch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfixed_batch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1143\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1144\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdynamic_axes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdynamic_axes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1145\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1146\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodule\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodule\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1147\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1148\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1149\u001b[0m     torch\u001b[38;5;241m.\u001b[39monnx\u001b[38;5;241m.\u001b[39mlog(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTorch IR graph at exception: \u001b[39m\u001b[38;5;124m\"\u001b[39m, graph)\n",
      "File \u001b[0;32m~/.miniconda3/envs/ccnn/lib/python3.11/site-packages/torch/onnx/utils.py:677\u001b[0m, in \u001b[0;36m_optimize_graph\u001b[0;34m(graph, operator_export_type, _disable_torch_constant_prop, fixed_batch_size, params_dict, dynamic_axes, input_names, module)\u001b[0m\n\u001b[1;32m    674\u001b[0m     _C\u001b[38;5;241m.\u001b[39m_jit_pass_onnx_set_dynamic_input_shape(graph, dynamic_axes, input_names)\n\u001b[1;32m    675\u001b[0m _C\u001b[38;5;241m.\u001b[39m_jit_pass_onnx_lint(graph)\n\u001b[0;32m--> 677\u001b[0m graph \u001b[38;5;241m=\u001b[39m \u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jit_pass_onnx\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgraph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moperator_export_type\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    678\u001b[0m _C\u001b[38;5;241m.\u001b[39m_jit_pass_onnx_lint(graph)\n\u001b[1;32m    679\u001b[0m _C\u001b[38;5;241m.\u001b[39m_jit_pass_lint(graph)\n",
      "File \u001b[0;32m~/.miniconda3/envs/ccnn/lib/python3.11/site-packages/torch/onnx/utils.py:1966\u001b[0m, in \u001b[0;36m_run_symbolic_function\u001b[0;34m(graph, block, node, inputs, env, operator_export_type)\u001b[0m\n\u001b[1;32m   1962\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m namespace \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124monnx\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   1963\u001b[0m         \u001b[38;5;66;03m# Clone node to trigger ONNX shape inference\u001b[39;00m\n\u001b[1;32m   1964\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m graph_context\u001b[38;5;241m.\u001b[39mop(op_name, \u001b[38;5;241m*\u001b[39minputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mattrs, outputs\u001b[38;5;241m=\u001b[39mnode\u001b[38;5;241m.\u001b[39moutputsSize())  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[0;32m-> 1966\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m errors\u001b[38;5;241m.\u001b[39mUnsupportedOperatorError(\n\u001b[1;32m   1967\u001b[0m         symbolic_function_name,\n\u001b[1;32m   1968\u001b[0m         opset_version,\n\u001b[1;32m   1969\u001b[0m         symbolic_function_group\u001b[38;5;241m.\u001b[39mget_min_supported()\n\u001b[1;32m   1970\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m symbolic_function_group\n\u001b[1;32m   1971\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1972\u001b[0m     )\n\u001b[1;32m   1974\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m:\n\u001b[1;32m   1975\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m operator_export_type \u001b[38;5;241m==\u001b[39m _C_onnx\u001b[38;5;241m.\u001b[39mOperatorExportTypes\u001b[38;5;241m.\u001b[39mONNX_FALLTHROUGH:\n",
      "\u001b[0;31mUnsupportedOperatorError\u001b[0m: Exporting the operator 'aten::fft_rfft' to ONNX opset version 17 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub: https://github.com/pytorch/pytorch/issues."
     ]
    }
   ],
   "source": [
    "# from core import ExecutorchModel\n",
    "from edge import ONNXModel\n",
    "import onnx\n",
    "import torch\n",
    "\n",
    "torch_model.eval()\n",
    "\n",
    "torch.onnx.export(\n",
    "    torch_model,\n",
    "    torch_input,\n",
    "    f\"{name}.onnx\",\n",
    "    verbose=True,\n",
    "    input_names=[\"input\"],\n",
    "    output_names=[\"output\"],\n",
    ")\n",
    "\n",
    "onnx_model = onnx.load(f\"{name}.onnx\")\n",
    "onnx.checker.check_model(onnx_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exported model has been tested with ONNXRuntime, and the result looks good!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import onnxruntime\n",
    "\n",
    "ort_session = onnxruntime.InferenceSession(f\"{name}.onnx\", providers=[\"CPUExecutionProvider\"])\n",
    "\n",
    "def to_numpy(tensor):\n",
    "    return tensor.detach().cpu().numpy() if tensor.requires_grad else tensor.cpu().numpy()\n",
    "\n",
    "# compute ONNX Runtime output prediction\n",
    "ort_inputs = {ort_session.get_inputs()[0].name: to_numpy(torch_input)}\n",
    "ort_outs = ort_session.run(None, ort_inputs)\n",
    "\n",
    "# compare ONNX Runtime and PyTorch results\n",
    "np.testing.assert_allclose(to_numpy(torch_out), ort_outs[0], rtol=1e-03, atol=1e-05)\n",
    "\n",
    "print(\"Exported model has been tested with ONNXRuntime, and the result looks good!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.11729550361633301\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "\n",
    "onnx_elapsed = 0\n",
    "iterations = 10000\n",
    "onnx_elapsed = []\n",
    "\n",
    "for i in range(iterations):\n",
    "    torch_input = torch.rand(torch_model.example_input[0].shape)\n",
    "    ort_inputs = {ort_session.get_inputs()[0].name: to_numpy(torch_input)}\n",
    "    start = time.time()\n",
    "    ort_session.run(None, ort_inputs)\n",
    "    end = time.time()\n",
    "    onnx_elapsed.append(end - start)\n",
    "\n",
    "print(np.mean(onnx_elapsed) * 1000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "machine-learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
